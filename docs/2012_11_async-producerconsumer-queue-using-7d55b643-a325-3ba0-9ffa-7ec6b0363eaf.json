[{"_id":"f3ea5f9a-8aeb-3de7-a2e7-f30d5758d355","authorName":"svick","authorEmailEncrypted":"","authorEmailMD5":"","message":"Having multiple consumers in your “non-dataflowish” way would still be quite simple. You don't need TryReceiveAsync(), TryReceive() is enough, because it does not block.  \r\n\r\nAnd I think your example with multiple consumers is not very realistic. If you want to have parallel consumer, you would use one block with MaxDegreeOfParallelism instead. (Unless each of the consumers represented some external resource. Which is an idea I'd like to explore more some day: using TDF for managing computations distributed over several computers, though I'm not sure how well would that work.)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2012-12-01T21:21:48Z","timestamp":1354396908,"authorUserId":""},{"_id":"0ba63598-155f-3ab5-aa2d-7f8b97681c69","authorName":"Stephen Cleary","authorEmailEncrypted":"XeAWUqey55w1zSCz/C358TFpOQ4pNgHGYWD27LLQjMGtwwg99A8glka7PQMgXLYPpD5YjSFztkSXW+Y7fKXLuERXCPJyIziZ7qjzeRb1B80OIbm9JIx6sRFIj5RndmxW8XMD5hFBSSLymEb3E4/Sf6SPHB5D/dWV0m342v7lVYZ8iqdNdR+oN/aNSRzcutKFInyhKMBaDN6gphZMZj3kQX+QRCObzrNpgwaxG9viL5WGW5bnYqzIfyCAqphpshm72s7yfHT15YJkumHWMaJtHjgW8/vb2hrTFxox1TTVW5RW9M2W9FxUnwo3uieTknazRziDpo1XLMaGrFkANnfx15djy6Qh+wNdQnb8/0R+fvrK+KuhEUToGrUEeHckv+PSmQnrmYqFeEgX6/VXaeyxujE2OJHXsWGPS3EBM0djBTluGGmLBOeWj6ry5maiBgHRhtNSUnElUIXC5jdwrh6eYsNcwg8QZNamMKZcueg6pPE1iCYIDD8CpBUoDJI03nvXZBQ5iurGjOqtcRNpncENDSDDXmku/nB+/LRu5X9hAcLFvD+D/SzgpPNZuBq6aMaYvOnASGHcPqyxzLu5RMw9bpcVKAUAG0V17bT2qy8OOe7laA0y1sDruPeXuzgx2lVH4+/xcj7Q2wuIpnRFicBR1INC1ylq8dtOQqbGPq8xtYA=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"In my examples, I was using consumers that wait to receive. Synchronous consumers can of course use Receive, but asynchronous consumers can't use TryReceive because it doesn't asynchronously wait. That said, asynchronous consumers are probably a rarity.  \r\n\r\nAnd I agree that the multiple consumers example is not realistic; in most situations with multiple consumers, they would all be doing the same thing so you could just parallelize them as you suggested.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2012-12-03T00:09:05Z","timestamp":1354493345,"authorUserId":""},{"_id":"9ae6e8fa-aef5-3943-aa2c-e58a53192864","authorName":"Stephen Cleary","authorEmailEncrypted":"CfhrB8wLZatSQusShP8xGNFGEpfyqgPLs2rnCIX7vpTI7up/jWr08wIDBhzD8KcqcXyZjH4DbBU+hMMxw9oXnpruttRPhQIZ0Zfpm/o9K8fV+t86M1h1vo7TbLJueUtXq7l8u8Nxf4B6W97DNOu2VY0WqxPm4eu596WqbQ8YHKDQns7ytFX/tRCF0xcTH/Vh3725GiHUQd7uADH7aeGIWvrNVah48YNqFLGmQscI7RvlJr9+vhBtajNd99BhTNvoGoXF0tfbisKTR7s+7hkj/V0hQLeTG1Cd+QGiJt/Ssr2QNqzEE+C4+slPKH8gwbI2/f3Au4pQVsabcaHQgMnHUrFScbu5T88Cxv7HufGxilRIp6BkKLlCWggKdsLrtY0U2XjDTgGBCstaJioihvW33awaGWDPZwvEHK+ss360J67YTk+kPL/iF+mZS1oqFaB8AAX5pGC8iO/6zvBrO7fX2yyQ4JeFt60KxDThaZl7Rr0ytDFnipBAUYwuOREsDI4ZywNiz+w9vb8irnRj2frxAspk6g3vp8XlAQH/xj4MHUiwqZdl1qPMLGaipu1jHPYmQM6p3Q1K359F0MC8TGPHXLeYi1NYB8WNL/FMwVXinjd7vMRGv+ehRDoL41Om4Z/jIbYBgZBAU4CFW52/nZHGn8SrDdGeHxGJSHBmRoxLlPA=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"It sounds like you'd just want one consumer that could process in parallel (my example is more about three separate consumers; they put the results in different places).  \r\n\r\nIn your case, you can set up a dataflow with just one consumer and specify the degree of parallelism in ExecutionDataflowBlockOptions.MaxDegreeOfParallelism (by default it is 1).","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2013-04-30T16:44:12Z","timestamp":1367340252,"authorUserId":""},{"_id":"fb6f9467-3054-3aaf-a9e2-14d0a92431a6","authorName":"Anonymous","authorEmailEncrypted":"","authorEmailMD5":"","message":"Excuse me,  \r\n//I've read your post but I got a question can you provide me a sample where I call different consumer in parallel?  \r\n\r\nI've seen this  \r\n\r\n var consumer1 = new ActionBlock(x => results1.Add(x), consumerOptions);  \r\n var consumer2 = new ActionBlock(x => results2.Add(x), consumerOptions);  \r\n var consumer3 = new ActionBlock(x => results3.Add(x), consumerOptions);  \r\n var linkOptions = new DataflowLinkOptions { PropagateCompletion = true, };  \r\n queue.LinkTo(consumer1, linkOptions);  \r\n queue.LinkTo(consumer2, linkOptions);  \r\n queue.LinkTo(consumer3, linkOptions);  \r\n\r\nbut I prefer to call them with Task.Parallel so I can parametrize how many consumer to create...thanks","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2013-04-30T16:04:54Z","timestamp":1367337894,"authorUserId":""},{"_id":"9aa2d887-1e40-3d42-8d06-93c8779f7bf5","authorName":"Robert","authorEmailEncrypted":"","authorEmailMD5":"","message":"I would appreciate a suggestion on how to implement efficiently the following scenario.  \r\n\r\n- One producer prepares request messages which are submitted to a \"component\" which consumes them and replies back with another message (a future)  \r\n- each message can be processed by a consumer in maximum 30 seconds   \r\n- the \"component\" which consumes messages cannot process more than x request messages at a time  \r\n- if the \"component\" is completely busy, a producer should wait for an amount of time to be accepted for issuing another request message. If the timeout expires, the request message is dropped (as cancelled) and another request message can be processed.  \r\n- the producer should be able to await the result for each individual message if he wishes. Practically, for each request message a \"future\" response should be generated which can be awaited if the producer wants.  \r\n\r\nIt seems like a good fit for the subject of your post but I am not sure about which async/await constructs I need.  ","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2013-08-28T02:10:16Z","timestamp":1377655816,"authorUserId":""},{"_id":"e3991af7-4e6d-3148-9820-91cd85879108","authorName":"Stephen Cleary","authorEmailEncrypted":"KACQQ82U+m55yAM4lRcFJMlFrYBTdpvTKMqobxQll/tW0AscW9BE/xV0fYe+fB1LmL/PPbU/MJ5LBd4RzxowrM0n3fsmIkiIioAJBoT5gKfO5KDrgsMlLL+sgGWcHNrYVZyl6loYE7yuCXPrrWemP3YRHzd9nNsMtVUq033SgXZI2f6+7wDZFIGnwUHT1gVDZ5ye+qYoDzJ/un78Srsn3uMB4QEnTdvmsJSM480aZ692UdZ0nVCPqO7xBcaXxxAmMmRDjviA9hdXSdwN7bnLbydpXrlDDDpXVhYb4tIpGWweKSymZEP38CYeFrfRLtyelMoMyJOzopXvsOKXPaxk9LV8t0AIwtqxyrEHaCLi8noSVjfMi0a+J/UVz3Bz5710idrrCk4rd4DwUx71pm1jvJsRERZkms8nIA3BgNYkS6ndmzOj/leuKf/pFlgIkEQ+eywjwMA6p1+hmWSZsGwmpRciuWHsDYsUZRrMes+lysZ3i+KCu9wjoh0sOpbPeAYZZSTXmeesDLQkeOht/jxP45wVLQnqvNreWgiu2vUk5b9bw/x8WUl9CckIa5RdG9cHSyw6fCh+J7QCl16TXND7iCIjO2wKEuESpGwR1iHWI4C3f8GluGiREc/SoGVEn/reVUMkpPErHzjFzSsmcqD9elDaezRcQ47q+LpHY3v5y9c=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"You may not need TPL Dataflow for this.  \r\n\r\nFirst, you'll need to add a TaskCompletionSource to your \"message\" type. This will act as an indicator that the message processing is complete.  \r\n\r\nNext, you'll need to handle the throttling. If you're using TPL Dataflow, you can just set BoundedCapacity; otherwise, you can use SemaphoreSlim.  \r\n\r\nTo implement the timeouts, use CancellationTokens when you send the message. For TPL Dataflow, you would pass the token to SendAsync; otherwise, pass the token to SemaphoreSlim.WaitAsync.  \r\n\r\nBlog comments are not great for sample code. If any of this is not clear, post a question on Stack Overflow and I (and others) will take a look.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2013-08-29T20:08:00Z","timestamp":1377806880,"authorUserId":""},{"_id":"f923cc9c-42b3-354b-a3f3-8d9da809a89a","authorName":"luizstangarlin","authorEmailEncrypted":"","authorEmailMD5":"","message":"When implementing a WCF custom channel that process messages N:N, you end needing a totally asynchronous Producer/Consumer . For example, messages received can generate zero, one or more messages, same way on send channel.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2014-01-15T01:59:53Z","timestamp":1389751193,"authorUserId":""},{"_id":"0c68d212-a193-390e-a2d4-016074e0b03b","authorName":"Stephen Cleary","authorEmailEncrypted":"uTpKCNNIUHgWXe8vwCMg+uh24Fv5driialzePP3ElhamYGh31qNi8IcHWdRmD5e7PQC/lkeA9FZp3vXy5Wy6IkGUhvUy77e+GKMxJEVNamQO9zYNdJ6gQfg16f7I5HTtalHTahPof6OhycHyZydbzDClou1zAaMMzDynCVZi25nI9LFJAJih3/VtSwS7ATWNNf904AdqWzxI49PxeZEu5xoF5fax6NTvuXe4qkvncbPeJUrr2MeS44BkMB1Lr18b8FS4vFbJyvkhldriWQARGGr7eZgRFoGqefIuNf1Mzxgyrizbheel6ntfheXgIi1FCeRm/pM7QRiEMx7s97TQgvlWAbNlAFJjvjloKpkxysFzDC5PO7mXI4NEc0J15sLiWKhvWcVMslq0uVSU14/Dheg/ljAANZfhwJID5wxK+prd4Pim35QCyhSWHWzTT5Ko/vI+jRQebwCwAP22cCwBsnElAUumoWoKOeqaSvxiHP830d48GfzfVi035QI/ULDk6ndyY4LxpoIxn4O3jyFOGZH1Nzcy3/lv4JAji/3JnMlUU/3wO9jvLPuJmIGOE80SaRZAwbobs13/fIlMDV5L45IPo18viTByd0FMsmUEaUcwSOUtXiOuYYLJVpFGMlK3jCLxA8UimfjM95XW9RGaM+ViEvH0GQEKuuZJWQDNQko=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"I've never been in this exact situation, but let's see...\r\n\r\nWhy can't you just call TriggerBatch as the last thing you do in your action blocks? You'll need to \"prime the pump\" with a few small batches (as many as you have action blocks) to get them to the action blocks in the first place, but then it should be self-regulating.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"7dca2dbf-6224-3846-b867-136c87aca7a7","date":"2015-09-10T16:01:57Z","timestamp":1441900917,"authorUserId":"disqus:stephen_cleary"},{"_id":"7dca2dbf-6224-3846-b867-136c87aca7a7","authorName":"xenonforlife","authorEmailEncrypted":"Ecb09dnUibDIrsTiHcTVn8ENoytsa1ZduJ7FJrvnAiYiu2jEoM2DJqtG5+msivHMYJZkTixAPsopQQfRzQP7+SQY20h/B2nee/4AtGUb/icxjRVW/XeGTKY7ax03LqXaoXAIbeNrPx38Pxg/1+bvmkGJEP2EMI3fYVMQWDtUF8w0ObGx6aEN3KgNnuYPkygOuLx5HzMruH6ZTddTJSOG/RH5Vc2xXkN4ukrd3YnVROK2MHIXUXApOg8TcDIp+IS0rPwAhW2SrkamBnobCxIvMazVY+GrIxp002FVLICy/TjQ/ETL2NL8kESQUHelTqPaCHbJsJ16aW4+Tzx7SNVxVFqvBQtBRFUTlxWOmjNzPeheYe5iRHoMoIYuFFGG6y3Wd5k37gTVTIojCM9ESw6Tx0z453hRKuAwNUKJJiPm0ez6TW3dQVanvgcnyZn4gCQmu6hfRm5pEan8Y65OTC2ldEIkgAmvXnCLxB6RBB7eriX2+bQwz5v3mE4drhjFhWJ9DGRjIcg7fQ3Q/0W9SW1Di2LDanTp9RIVIuj4uTYeA1E62X/NU9+Qdhj7A4uGUfITKt9Lgpe3Z5C9Sa9i+Z5+vvdoy38RmOk+C//zk2mHiyN+7Gx91AxXiE6R3lZ4GKSZIfYroNGoL5ndF/RpjNBfge+74Uw7Ew8B0ifaLzZ4in4=","authorEmailMD5":"678244a0ad782aa2a25518ca6168b046","message":"I just hope this blog post is still alive, I am just learning how to use TPL Dataflow and well am getting confused over and over again. I hope I get some insight from the expert himself. So in my Producer-Consumer scenario, the bottleneck is really on the Consumer end. I have multiple consumers as you, and each of the consumers send an action to external hardware, which may take some time. My Pipeline looks somewhat like this:\r\n\r\nBatchBlock --> TransformBlock --> BufferBlock --> (Several) ActionBlocks\r\n\r\nJust as in your example, my ActionBlocks are the consumers. I have assigned BoundedCapacity of my ActionBlocks to 1.   \r\nWhat I want in theory is, I want to trigger the Batchblock to send a group of items to the Transformblock only when one of my Actionblocks are available for operation. Till then the Batchblock should just keep buffering elements and not pass them on to the Transformblock. My batch-sizes are variable. As mandatory, I do have a really high upper-limit for BatchBlock batch size, however I really don't wish to reach upto that limit, I would like to trigger my batches depending upon the availability of the Actionblocks permforming the said task. I know I should use the TriggerBatch() functionality of the BatchBlock somehow but am really running out of ideas of how to approach the problem.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2015-09-10T15:11:54Z","timestamp":1441897914,"authorUserId":"disqus:xenonforlife"},{"_id":"fe0183cc-1a55-33f5-ae78-d0555b1d62e0","authorName":"xenonforlife","authorEmailEncrypted":"nHebWlrPMAMuDN+Q8uvgthzid3F/SoPY3gfS9Faqvnpw3lAXdmhlaIKi8mOFpUim5w0uKvee9yuHZ8mu0Wzq0ghw2PTmNayMCScz5F3J4UpKu2Degd76LovK3I5ynK7MPcMLEbnLo0df5Rn7g8LSkkjM6ZHYWU8SW5k5iCY+Grxe5As7K0qhKSZh3StyV5KhFfAjqUF1/UclKQcd63OYbiOebHXqAzUzkOVksnvlO5t212JaRcwRtOl3C++5FSlGKVaQ/PrxvGhjlUyO+6e/FslF/m3ELuMn6MjQ+zRcJuohbN+72/ci98rf22b4t2mAT1sQ9bdVo3f1xheC6P2DRAolOLm32OLsaMfkfR0j04FwU/SnaqyRsN6tVl8ZGDXG9NjpflbD+o4ZeC1/xFLEcTXfWoyQCGTkj3vauM3qB5R2s5IZ4Jnus07vqNlYFHBT6LsWEvckhNe2sL5VaCI9l50NVWfBt/GbbiNvr6e28FOXj8jm+w7SSurA3FprMYHmTzoBOJInLxloKvQfUW6ylF0xP7IWwAoJgJJnKhxQ/gtxH9uEQJXK0Zf5G4RkKy2KjsEnNUjJGj9wZZ6l10+NTYP+T0Nd2Qyr6iQfJsKuip7OBKdsEQYrDWXWWRCTIWD2WP3umntE5ahxJhiiDYvO8sWhgNxPK3eG7BfOCZjlJCk=","authorEmailMD5":"678244a0ad782aa2a25518ca6168b046","message":"Thank you so much for the speedy reply Stephen, I did think of this solution infact but then this approach poses another problem (which maybe disadvantageous in my case of contacting the external hardware) that as soon as any ActionBlock is about to be over it would trigger a batch, therefore I would somehow run into fragmentation of an otherwise (preferably) larger batch. The next thing I was considering is triggering it from the TransformBlock (as the first thing in the transform block, here too in order to start the pipeline I would have to start it once externally but after that it would be self-regulating). This way each successful propagation of a batch through the transform block to the buffer block (after transformation) would trigger a new batch (wouldn't it?). But in this case then for a smooth operation should I then set the BindingCapacity of my BufferBlock to 1 (or equal to the number of actionblocks)? so that when there are no actionblocks to accept an element from the bufferblock, the bufferblock inturn stops accepting inputs from the TransformBlock (and this is the point where I am getting stuck, since at this point the pipeline is self-regulating wouldn't the transform block keep buffering its output if the Bufferblock is not ready to accept it, since from the documentation I could understand that this un-accepted output would be postponed/declined, but I am not sure how that works, but this is the point where unfortunately I am getting completely stumped)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"0c68d212-a193-390e-a2d4-016074e0b03b","date":"2015-09-10T21:58:44Z","timestamp":1441922324,"authorUserId":"disqus:xenonforlife"},{"_id":"2d8275b1-2593-3951-b084-fa24563a95fb","authorName":"Stephen Cleary","authorEmailEncrypted":"dcRwDzZrsCXHvvOiiVeJshAvzGTdtN+ehwRAiysQ+qUit1G9FRDDzKCs0Qf16BeEs7p1quNqPd39u3T5du+whLMoxJF7ErwMXP0s8SzqQHnX2r8ti7X4Xw8A+VbOE6DdymT2VSe45G8HE1eBs5Iis59hIsul7Zr+t+zd6ZIhveFBSjTn2exMvxOuhjOtaP/CnIHyL8K4CwNWiFrwvferdS0jp0Cr2UimNPBjhbGoylX7aiimgjE8SnLBh3+fLFx7aJ4uEsd+DRDJ7ymEdP3QFhyi6v1iXj4xIUBu+JtgYpCNPYPEQLiMu3nUJv3Z3cnkaRmC2IaYXpc6zFFksJ0Kg8e/PsEjDArqBg3yUloxSZg04YNIDMDGK0v79xy6XnP6WVqkDMQxoJ51y5D0V/PX2PC2LLn62K5AIDhqOwwMJxhzaYRZ8E8mdXh8A18kY5/hKNdfQiIG14UhO41wE6zA/epY9JTccXq6r8Y/0FXxngzu/HuE/GIXrq7xXwtnI3vQPKzfn8d4ykk26IOO9GbudIN3FNS0WAy3GIiWqAwPHhjytIejr9eZ0O2DaUqRk2kvRirkaD5Xzo8JjTVDc9Ulh53U8zOGsbGSCOWycgDqFoBCD0VkJyaSgbW4MOaX7t+3F9Zj5D2/CRDj/4jXSIHv3RfrQYPshFagPlfifhCF/Ng=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"I'm not really familiar with your requirements, but it sure sounds like you're overthinking this. Most of the time modern computers have no problem keeping up with embedded devices.\r\n\r\nAt the end of the day, the best way to know where to do throttling (etc) is to just run it as-is and observe the behavior.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"fe0183cc-1a55-33f5-ae78-d0555b1d62e0","date":"2015-09-11T00:39:35Z","timestamp":1441931975,"authorUserId":"disqus:stephen_cleary"},{"_id":"a5934daa-8613-3be2-9f8c-eaaabb2d24c5","authorName":"xenonforlife","authorEmailEncrypted":"f92HiRPBTW81DWFohzU1awIBQYdKPy+ToZ5Sf+gZO0Ff6sDfdraxQjrIhaCYZm0cVN2w1jTW7P5vM4a5K/ivcjTsNklI1XdC3CBOdh7BScaIBd7gLfGRxvmn5iF6URzQ0mzNnhHhZcWbeOzlLwcemcaB/VXONt/u1jqbset5DWFjAIsiMiOKh8+hqIBGoqGM1DBXzYMywUX0R2dhRE7Ez/XEDSg97JTtGFHAI1l5InF1nGo9sVh0P6lCWVBKNZyHzXmKjI3QAuNgW0ykKBKQ7cQUE9okZW0aAH/R/G5NLNZhAC91XPtQqfKG9LnQj2NjwNcI1okPDAKnEhADN1Mw8Mz5i2pESBrC61s2l/+T87oDu1ljkzvZutz6VhtDNQHiQYswesOG5z2gp/jlMLFA45i29gOuQ9l5hIOcc8EAoJ7/eD1NBwD/QOvRzTDbRjYdYGZbhqePQrF2cQVHSH4ausZk8311H0/KusaAaZOyb9kOn5RCBRu8kuYglKgWVcAO7OLIPaYU/iI/XmE8Eob6PiRdozrd431Sn9aZWPgm7V9LrpHGiSX59j5rGoc1hRv1Qw+objOxMwLUaz/vg4zlT2RNwsyzb5wOTAuYwhGmUpB+MUfrqYFgYHK6ts4eEiCdcbsRGHdQ82kUNzZGJnVavkeWbVJaCwWSe9ftX1WHgLo=","authorEmailMD5":"678244a0ad782aa2a25518ca6168b046","message":"Thanks for the suggestions Stephen, after reading this, even I am now feeling that I am overthinking this maybe because this is really new to me, but I have to make mistakes to really learn it. I will just give it a go in small examples of my case and observe what is really going on. Thanks for the advice. I really do appreciate it!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"2d8275b1-2593-3951-b084-fa24563a95fb","date":"2015-09-11T06:14:32Z","timestamp":1441952072,"authorUserId":"disqus:xenonforlife"},{"_id":"349b05d7-a73b-30a0-a8bf-956cad81315d","authorName":"xenonforlife","authorEmailEncrypted":"nZ0dyw20ZAaa+IeIHLeo8xrhTN/74rg1v/3uDQiQScMAcQnACPACgsaU5mqE6EDfL9+lDk19AGimRw+79OkodkUyoIKLhjoC+cVEnEjzLd6NNdpujwcm3jRREkcR4Hj6UqHsVOgXKJrmZu6DKWvohB3ZKD9VwsEMx1fHy54Gmo1Mjsq0hmj3PEci0kiRZfo0b49hBHjnM4zqnbsnI79DvoUJfoZQZ9BD3npGazsZU0Ra497fS3KYJTJAiuwE0fBcqQWBJXQci/yExR9B8YVXFmCf+FIfnyyS041mjQDoOAIRYz5banQ3yhNr36h0lhwz6hhqQ+QzvraZMyGLwcydFzqSbEXm3fWzYP1ZHNIvcD4Cr1Z+v2yuES8dBfSDF8hcBV6cKp8ytA9aEX3VcmpHa2Qz1Vh9n3LIw09wE0v1JKl0/xDj/NsN+Ux2+xgQFSbmUqWFapnF3lMoNf93SXh6zKFTPy+T1tiiNdrN77DHojowmmMZyg99pw3QBPY/CDRgXIK22UU40nKCFYXvwEp7W9fsbg24pv1iBYogOEdlVlacokusDEPxeFMMxJbpRWQK4iOvv/pd90D6w1vUbc5n400viRYmcUA1LOCqq6f5403iLSZP8zGoY3g06V0k7Yp5zQMEQXjWgURTP0YLOELK21D3SH20+hLGbOQLwVabIp0=","authorEmailMD5":"678244a0ad782aa2a25518ca6168b046","message":"Hi again Stephen, Your advice to put the Triggerbatch as the last thing to do in my ActionBlock indeed gives me positive results and I did move forward with the implementation as well. However interestingly after several days of working properly the pipeline has come to a hault. Upon checking I found out that sometimes the inputs to the batchblock come in after the ActionBlocks are done with their work. In this case the ActionBlocks do actually call Triggerbatch at the end of their work, however since at this point there is no input to the Batchblock at all, the call to TriggerBatch is fruitless. And after a while when inputs do flow in to the Batchblock, there is no one left to call TriggerBatch and restart the Pipeline. I was looking for something where I could just check if something is infact present in the inputbuffer of the Batchblock, however there is no such feature available, I could also not find a way to check if the TriggerBatch was fruitful.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"a5934daa-8613-3be2-9f8c-eaaabb2d24c5","date":"2015-09-22T10:07:14Z","timestamp":1442916434,"authorUserId":"disqus:xenonforlife"},{"_id":"f6f03198-13f2-3a14-adc4-41f8bb8514b9","authorName":"Stephen Cleary","authorEmailEncrypted":"AokDElbm3kq9BXKenXDgBOwemBcal5SZpqDBILobc0b8oj2dzLahudSXmSD6WBAmkww6P0ndUPH89gA5S9y1Jsq4JJHTggXOjcF9D9y7G0QbC5v74sWqRbN+IbXkueEuskjfWdg1wKaHVtx2Pczz8pSWXkCusVpSvKnnN/yAFIT+chZZ1exS5C0YlErLzsAm4LB7m/mv8Fjw9HgGPwv4bNdAVmTWL9Ig4gMXEBKipdZcZx5+XlucPqecVr4a8rK7kDBO1/KLmN/ONry/Q33GROQsxLot/FkSlZdoqM8AcmZTrHoAKYCmuIZ9LCITxBsbfwFaS2TUZsN4x0r62roXOc0JFs+hU4fSKxWucRX8WqF1HQvHRSfr2nHmB1l5Xm3jPApGe/2dzzSUcCWyLXF0HPQbDKo759QRlOmlWrg4P4n8CceVB4XCOSPP3aK9Tm9f+mA22xIkHHKIuOfU/5t3vSDVCfROHQCJzG0n3EnbkdZNanuScC7djO7YvLT02N2/K23kUauBdyCTp1l/4QqwYwt2HxrArpb6F2ZHkNmL0ItLbkFzBqr9u/xvXV4dElVpVbLD6G6DmHt3HFtyyOw+1dZoV+aRjx6LLXgYSJlh5t3MQLAusbAGZfQJGfCvBJUO0EmAs0zKXyPkvA7IgSaFrz0rtB0CqgtVNN1oHXZ3fes=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"Good point; I'm not sure how to solve this. I recommend you ask on Stack Overflow.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"349b05d7-a73b-30a0-a8bf-956cad81315d","date":"2015-09-22T12:05:43Z","timestamp":1442923543,"authorUserId":"disqus:stephen_cleary"},{"_id":"7dbf9e85-1934-375c-8a19-40d0dffefdfc","authorName":"Stephen Cleary","authorEmailEncrypted":"vN5crLroMXn6faVJDJGyMEGZbHjCRZluRgClLFkoh8d+tRqxf79nPccEX9awO6SM5ITktsJxfqCFSIvXRz8YIYldHFmlXM13fdu6Fnqs6fjqFFul9v3X4II8geirZXhQC5eyZoq/3MjIISnSvebrGpNyD8LHZ/ya3q6B66awt+MJ3pjoxof3iUZ82r/rWdhTFMnBmZaQ7V+v7qdpo4VlMu1ItNan/hKdaoon9fluBD9RoeCnuI7Xpri6AiplXLK5JxHEtik3jhyCYy4+RlS4g7xi5jSlfgNL1XSknarb+8TrjwScwVtU/o1Y4LaghaOsCDBPqUoz+gWcRqRu7FLA+rztqq7UFvLB77dxKjays4yzMhzqL1t7qidQX0lqruPolkDjB26SHS/Q4W2rB9XxFH3DZ/AT/FTIjqbhX7ddykO6IQ23UHH8ePnFJjAIfNFDTG3j5Xjoq3/QuaY7liXVu9Wanwtj5cg8+56jshMm1vtVH5fGu7HroYJQBqd7ntqLtCZmR5xgRV/2w4d6ynB6PrQ/tty+pXFZulmM0RKXYvTA8fJKfoyR98D6QlWCSSKiInRm6oAXgE/nUCWEj8uhCZ69J3Es745kERkZsWAVGgO8o4+15rVUPc3hNWdIZUmdm1FigMxRYiDCynsVNbNnnERvZ3RBNod5dotk8QfuJq8=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"That would be difficult to map to a standard request/response pattern. It's *doable*, but not very easy.\r\n\r\nIf possible, I would recommend looking into SignalR. SignalR allows the server side to send messages to the client. Though in your situation, it sounds like you'd want to use a client-initiated request with progress reports coming back from the server.\r\n\r\nSignalR's progress reporting support isn't very well documented yet, but here's a small example that should give you the gist: [http://stackoverflow.com/a/26591235/263693](http://stackoverflow.com/a/26591235/263693)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"fc943720-3119-3c30-8506-c379ca49e776","date":"2016-03-09T23:30:44Z","timestamp":1457566244,"authorUserId":"disqus:stephen_cleary"},{"_id":"fc943720-3119-3c30-8506-c379ca49e776","authorName":"BPD","authorEmailEncrypted":"EfnO8W9nBeLjmKZm0Mtx4ms9VGJUDUjisWlqx5KpkQm/vt9Hq82aaiXKBdAY7+iM/uMzTkkoBZAr08gNHjh8DEjYmnzpbFQbA3nRf3HvQPDMREYOkxRinFO5b/BPWqt40eueCca9ywA9Kv1ZKbVNR5/V3OXNAd33Idolm1zr9a1Td5CZ5+3saHR6396aCacUnfBwsxEY7EpqSutVH0jl2wkUPtJUchOSiJRcGI6OOvDA9r0LulpjzUzlw3P5BTAJ7lh3VLIfZI48NBR+SBcU7fvUXBJroWPiIo8tY+gethWkj7OsJ0P8hc4ym1JJska8/6tpzTombWVNDHOlYdgFObaI5w42G7kg6iTmV40nn9ohn98n7Q9gddeu80mN4Z1M3vrUufDdpGVL5jv5RNvt07A41LZocmowwizvVDxNB9EG7B7VP5j2sTiIcqVzqmR1DOSXCbwVebfvP4YDS83OVCVwo3G6awf/H+44Bfqjcrw4DQgOITWD56vN/R0IFz1uVkHIxUK9pzCoa9HbOxpVoo/CmtTs00bxnfcPb7F40PeiLbD6qEn8/2MbP4Ufr48uQed3o7/bGlJgQUVGPTAZvEylmJL8KU07l29sMKekTzpQ3bHxef3T/09SrdonuP2weNiqVUm1S6l/ejCE6x14kLbUMHPwb0Gfi1g0J0mXu7w=","authorEmailMD5":"972d9371ad028ab56436fa052d2736bc","message":"I am hoping you are still responding on this blog. I have a scenario where the database response are received in segments(pieces) with a timed delay (certain milliseconds) for a particular request. The consumer has to wait certain milliseconds for next segment to arrive every time it receives a segment, but return that segment immediately to UI. In the mean time we keep receiving requests and every request has same cycle to go through. Traditional produce - consumer model seems to not handle the delayed response cycle well. Do you recommend a better solution?","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2016-03-09T22:34:56Z","timestamp":1457562896,"authorUserId":"disqus:disqus_lglbHNZnIf"},{"_id":"fe2000cb-f497-3b7c-9490-1a8206ca8f29","authorName":"BPD","authorEmailEncrypted":"uYHq5Fkc8oVx26u5IT2rZC9qVDD9UIOwXn8kKJdqrSi7JmItV0hm3j8nzvUgrCPYj96pLr3zMXQC9+SuLVNKATJN7RI6JtfP8SpXyDSkezPHqozmy/HYPVfGZ5Bx53S3KlT1Sr7M7dkBmvV1UNUyOiAHRr2nZ7bInziUPbFRXm6MKgRhRQpgcLWjX8woXaqsXeDslohLo0G/J4XxOG0mEbOTRwAJLgiu63q4PXZ8AhyDLmQCDMlj1P1x+QxrDc1SsFkwx483O/P3//UjmLXy7QvGeZff/iXOmkBt5cw/a3UyxN5wDklMOuaIJxHpLim+0P2aAYBSnepuY62EXMEs4E6KdvhErAaZExLq/PZlpfZpxiN9xWbPMuY1GkWpJK7g/uAz/SkOH6JsQBPXrIwNKi43gO11v19/YzvBnTmM4RBX14Ppt6X7q+4gYJpLCSLZQhWH2tyzAIjQ+ar8eUOg9zp0pj8Y2DKmG/GWU0pSxa7BC2NhTZ/GNvQP/bljEJF0lp035GOfUPIBO9KU8+YmaSkwXhJeV1fN9Lycd661wsWJW042jnfc11Yrr5wam6uXC8poRCraJCRvYztS/CV7S1tg8xBe1DVCIOBjiYbGylx35fWPKOGIpDdVPkRJedrMTUmfmoIsLQI27ABUJDm/LHCJ6MBvsOjLeTdvcMhRuPk=","authorEmailMD5":"972d9371ad028ab56436fa052d2736bc","message":"Thanks Stephen for pointing me in right direction. I implemented the progress bar pattern and it fits my needs","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"7dbf9e85-1934-375c-8a19-40d0dffefdfc","date":"2016-03-14T21:04:50Z","timestamp":1457989490,"authorUserId":"disqus:disqus_lglbHNZnIf"},{"_id":"15288893-eb55-39a9-b9a1-6a45056864ad","authorName":"Stephen Cleary","authorEmailEncrypted":"tBOoNwyUQVENDxF72r1i4KfMSAM9N+NDt/kH2XlkUJSbVSbqfVcEhktiUtS1ydg3mRCf+Xl1QU7uREgXYL793yAiNOwRmDJZIrFYjQVlpVeLbrq8LaLImIjy5syRP0elkdQrR8hYGktUzym5NG5eVHmnMWyzm1xI0WuJvHT9kCIkumMbhhs4Tkqm0KggcQU3ffpcYd+jgMjfgwXKIABMyOCMjRDopEtSmnVbnVJHy3SKTyySPBo/qc0iI0Z7PQClHNfjoLRsWGTNmN8fHNFZVu4E4YDGZeMhSjt8OOYWP0RpM4dv9n9oisNc8yw9j63D+ca/a2KOEetjElH9cvUq/NdWvEPzD6U+KQRJvJvJJNSCl+dJFStex8A4AtJMbbyj1UO9nU7iGmS/bufdywJLaTd+sIdsHVFjj3WSXmSmgXp2JOomT4MMvRMEzAMfzTVKTXp7Apkc7yWzIJO5Vp13LulHLc4asJTHZb17ZLxEQ5tsRsUH81yl9qsDXIC0oUdXj4UWLiE43yOLwjsZ3wsuuvnXayD9u4+356dujLUpweCAJm3NYWw6GnwdKT9j4c1J45N2U2KaLV/mXutn+lE/4XLJWSG8axPwMXeQrMCr2ymH4lNacf1wIwXad0QtfwdF/Cz1kEwJdDCW30K3+JKp1kHMTKcI3kRAGruLnRd5jdE=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"BufferBlock is similar to Queue, but it is not just a queue. There's a lot more to it, with sufficiently different semantics that deriving it from Queue doesn't make sense.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"e6085fd4-2d55-38e0-98c7-06daa91835e6","date":"2016-08-16T18:53:44Z","timestamp":1471373624,"authorUserId":"disqus:stephen_cleary"},{"_id":"a10a677c-82fe-3019-bb90-c0abd2c0ef42","authorName":"Buggy Squashy","authorEmailEncrypted":"HFR8pXJtQifRRQ/UCq1dhBzpG33sO5PrDEmMSyed9ydvRbGyRMfpiPFAb+WNTrU1iB2rCDvtRg/Kv/iOqV9Cxo/KQ2vWZGgSV9RvfPhXyRmb8LP1olfceflgpgmZ4Jrh/XpdA85VqzcwS3oO+jcDyzkokYbEYSsqpTU/SHBlDt4qjtz0L76G0imDdbMh8Yd3q/TDWp5AisHJx69+ee1ZzHCWlLo+YQ+vuOKz856m6i7jnx5wlXY2747OkHMc0mIE6Q+KDgdqmjwDfLEN3pOC4pL0YgaZ1xUfFWxdME7ObcsY3nWTojfIGd31lGcY9IZZyAfDDRrHuNNWklkVaY3ItPK4Nwvp6V/O2fQNXzPzAU2rXxhtGfHgqskRgqr2dBHJqJveHk5V4xPBMZL0wTZF5aNH7XplqnmTC1QrR4pmhwUjTe7LF2xqlW6eQKojjv6mPXCclImXf6uOOHrIGF4IN46iotLNrSqJ8DgKhwydkS3GcGWKtJwsnJUMgQd+sACzvss5lmma58eCqqgOWZ+u/EcKEhAfYVpKwmcaxLbQLMLKwdnIKb6suyC4KomoltZAjrSvlMrVZgF+J6ru10p00CUX/FBHGWXKeUsFrqprs/EMMlpIIC3LH9OxOwwYE9Nhu74DBoZuQfLfqCG+hx48rx5GXKStq3ZTdjZmZX+0Cd8=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Appreciate your response. I guess few more questions - (5) do your Produce/Consume methods have to be 'static'? In what context would this be useful? Reason I ask is that I don't want to use static data member BufferBlocks as well for this, and also I read somewhere that using static is not thread friendly. (6) In my situation user selects a number of cases and submits them to run, upon which, my framework \"produces and consumes\" the resulting queue as you showed; based on this it seems like my case fits the single producer, single consumer description, am I correct? (7) I am trying in my initializer do just like you did, but instead of a constant, I am trying to set the BoundedCapacity to a private int data member MaxDegreeOfParallelism, but I keep getting an error \"A field initializer cannot reference a non-static field, method, etc\", any idea why I can't do this? Does this mean my private data member MaxDegreeOfParallelism has to be static to initialize like this? I confirmed that works, but could this have other implications as a result, as in (5) above? (8) You mentioned that each item is immediately removed before its processing begins. Does this mean that the item is removed from the queue in the Consume method as soon as queue.ReceiveAsync() receives the item, in your example above? Also, if I understand correctly, the processing on an item (or in my case running the case), if any, has to be done right there as soon as the item is received, right? Thanks.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"a91c41db-eb22-37bd-8dfb-9de70b96158d","date":"2016-08-16T19:45:14Z","timestamp":1471376714,"authorUserId":"disqus:buggysquashy"},{"_id":"a91c41db-eb22-37bd-8dfb-9de70b96158d","authorName":"Stephen Cleary","authorEmailEncrypted":"JZlAWVQUxB56ZjL3cOxV8S81cnOR2pic+OvKDDw/N3urSNHKswY5KK4u2xoch1QiZxJQ5MnzKvn/sPmjNOd5AGnmcY1scZY2TlH+5Id+ML8N4Uzex5hoe1xHRzarN0VpwF5ol5TkdlJL1XsAU2Ci2MqKuHJts1nkmsUzDI4t+PZ3oLR8EwSZTCTvHv8pQYIoFB0mAuYBsxRPIbEnwx5k6dppFUS+9mZ4tTMHMEp1WTYq3GeL2grcSE5nP+6cY/gMxnUZdrZJlCeg75y+SZDAavnF9H3zXSqshqwVRot6pVvMS7yzsYwlf4lMlbFk1ikKsBFUF4a8Xei94xRiZ6Vj4tbj/+faV9BqHyudCN7BNBffwICHQ9RyUt5npZEwyvTtVTb9xZYPmoKD5TXuwSyuBlk+WoU1VZPExqXfXNbqdblvBBMyxngBsY9NSNqD97JvN9C5efe60ci6F7/IZ4L5D0nPfwRy5PYwgqqOTKgTmcSJ425gaEvX09pC1HJmIdb/qEZtVTqqiLfvD8QsAzQftxJRcf94gBkJX2he1GAvhtyoH6lBInc6P4rwQVdN+8frfa5WORJ9OvJS5q3Gxm/kpxEMDRBmS+KKSeHm5H9M9AufVja2f1wcfhFz/0c67mXBBCrt5C0yryjlRlwITVKaHaDaM1XlSp6j7xrzCY+j32o=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"(1) No.  \r\n(2) There is no built-in way to do this. If you need to cancel an individual item, I recommend sending a CancellationToken along with each item, cancel them as necessary, and then have your processing check the CancellationToken and skip processing if canceled.  \r\n(3) Yes. Blocks are class members in most real-world code.  \r\n(4) As noted above, it's not possible to remove items from the queue before processing. Technically, each one is removed immediately before its processing begins.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"72580076-b47c-368e-bf85-0a8c9c39e725","date":"2016-08-16T18:07:26Z","timestamp":1471370846,"authorUserId":"disqus:stephen_cleary"},{"_id":"e6085fd4-2d55-38e0-98c7-06daa91835e6","authorName":"Buggy Squashy","authorEmailEncrypted":"esiJx1oaGCmCWUNJElu1SjK627/QaTiPU1++rjb/CyXzcPyLXmVEe532uf6KaKBH4uW5BNGis/P73DR/22BZk1g3YabvbUMnF04EJwjTF7+BOldnfwh5GJHyscwr7pxaqSep/4NvfqRo1UshOa47LxvMZSDU5DX9iO4gdRaoICnOKVZCD/N24GzDmiAhQGq0R6H3j9aZ7iNnFf7vUxjEoqwdWWDs/CKSO2DJ9u7+TR8LmgxCbLcjatrp/skhJTuvkr5Av3fbDSFWwTyWdBBxy26jnO4REct6vwJDfjM7OEWuZWDsIKjeaziczk9YE5jM8rBNOZ9oyLZyAM6x8yLQKz9311D5E4G/9Q8e0xGxIbD2oBcJvw4AsSU+T9s6Ci8Fy63avspDbVYCtkPvS+p4tLBuAmEPX6CtSVbQCVVjFh9pMfw46o3h67SWtkuWm7hJnt1pWJlnn0n/+hU8XqlqJURMVhK85fFOMqLaAlrKZBcekhLBntiURcw0ayB6w2z8T2tFwyWFOxpJ54x++7fIl2JOhPAIP99Y5yqXVg2iZlASKXR7WomUcI44PaXnBh6gE/eE9FobZ1dxfrGn3AWFDumsvLBWKSUuF3Xgk2UqlJsw2u2tA/b2RZmqvrduygRvqnPeJNZS2YU05xR28UtyJXTNk3zRJb2EV3239YDTAhY=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Thanks for the response, it helps. For (1) I recall reading I think somewhere in your blogs, I think this one: [http://blog.stephencleary.com/2012/09/introduction-to-dataflow-part-2.html](http://blog.stephencleary.com/2012/09/introduction-to-dataflow-part-2.html) that the BufferBlock is a simple first in, first out data container, hence I was wondering if it is similar to queue in that regard. I'll work on the remaining as you recommended","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"a91c41db-eb22-37bd-8dfb-9de70b96158d","date":"2016-08-16T18:27:44Z","timestamp":1471372064,"authorUserId":"disqus:buggysquashy"},{"_id":"1f0215a6-23f5-3334-85d4-257c87ff45eb","authorName":"Stephen Cleary","authorEmailEncrypted":"iejQVanCdIrCfBSdtkU0FJDROhv2JOGGnxF01nASnKRTusYHwDE9OYRrixVEYJ14Ka0C0FcAakzWigOP3SU6Elz1qv5fTZVd5EDBAWr04Nc/tvbcGJfAcwG9kx5LoB7lp7W3t5uqqwCjUoc82Fsf72ut6QQTo1rrTpTZTxGu/zKJJJ+gCuwgqS/4uIhMdh/R1jjqFNamtFMqM4kEwLml5ueVqeffeboZjwRz8piLwpFSzsg48WVcXGifRvIsqKnVS+/Y655O4Cb1DYwoOabaTbTQmZ1uV5lb4RJaxMlBhz6btLNHdvnFDD9zpn3CdTX5ul7KBsC9j61PSqXAZXPUCoVUUIPFYilD06jmMeLAqmPPUVmvLyoe44QJs/u4BZi+Fs4Pei7Ls5SsHtlsn/4HfYtY8RQChFTEPEN/dJol/zkikDu4pPS+eHghZsjG1SNVUKhFdogazf19jkEUp/ByEQfZAmuiwTFgiHPcXbD0zVEvQg7WiCZVogCeq583FOd60UuFLfvUiDA2fskTuvTLMKRcQlqdpN6SnNUTIb3tVvyC1abnOjbU7GjPXtxO0eHtsk+M0mFJgtArOY1vnIp0p8V+Rsvt6BvWEgFMxRandFs1QLGinoQg86pOjIOYaq6bdUSIGoWiN8PiXdtsqFwMfCgPbcXrujFwZW4cOvBSLNM=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"No. Multiple consumers means actually multiple readers. It's a rare scenario, but useful when you need it.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"42a4afb1-9deb-3a9e-aab8-a6b7cabbc5ac","date":"2016-08-17T14:39:56Z","timestamp":1471444796,"authorUserId":"disqus:stephen_cleary"},{"_id":"42a4afb1-9deb-3a9e-aab8-a6b7cabbc5ac","authorName":"Buggy Squashy","authorEmailEncrypted":"SLJ96gxD+y9tziSPvycDEGewXPawSxs5fsl5ihNAGJ6bgKJNOYowQ7DpCn7WAMrMwVG/11cmvAro2noRoYcP+ewXKQBPBlzUu9NbiRPn3RNxVSv1Gf/I9wlK8bpAVNCk7Q2Vl2Z+lMGwliNc6e/VfwOedEQ22Ze7PZiZnCHUgayh8m/tnQwnWcqab8uXkE071vnmNBiOOwuEW8J+zQ4K6D2hjTW/ne8+kVMJAcOlTDytyqiaC/nngMjAhSlCNban0Wn0V804/lgHXcW53A5sw7OzCiH0VipwrGPqAX5A/yfvCHRN/QjYffd/JzaOsAu0DA6tfCl2SwZVl592mFDMEXmM7OaGmSyBKWrbte41AVIgvbnqPD1IU2GfCONWYh7vUuLC4k0900zKRLFkGWu5+GaPsqczaoW34tJaQxFVh1zcSUG5GwCUHUrvrkKrdXBP3WOm5J+XCbqrGBYN3DTdIiW5cXjsRGglHOkovH1BRFWMEzi6/qM8t9jtSOinx1LC4nP4/1agxph8mHT3zevQ+0xbRnGB9mCoj3fr7wYm8B9muDx6L0AB5gqiw8b4WGY0OtxBOy4eGuIH+34d2/iP38+osjh8DT7rTISy/j2ieaEY75iwmLTQBnIEUzsVIJFXgo5P5vZtzFRcb5g6jC0xspdQ00aO4WGQ9Blfd+OoBW4=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Thanks again for your patience. I guess a follow-up for (6), in what situation would I need the multi-consumer pattern? My user after selecting a list of cases and submitting to run, might then repeat and select some more (possibly different, possibly repeating some) cases and submitting those as well..so would this make it a multi-consumer?","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"4a1c6ada-6397-302e-ba80-f60356433c07","date":"2016-08-17T13:55:31Z","timestamp":1471442131,"authorUserId":"disqus:buggysquashy"},{"_id":"4a1c6ada-6397-302e-ba80-f60356433c07","authorName":"Stephen Cleary","authorEmailEncrypted":"vf2HZglWcu/HDbKJuNX174YaP6D2bElfy9QFiCgdQZaR7HpTLYefQGErzmgs3E59vinu5i1UF1MSk5E5TzJrq1Few2fsoTya8LGIq9Qmu/Mi1XfI2hz7YUMU7vFvd3ZmCiDXEsYojYSb+8k2LesfMhXTzrQzZVWFZQs8wb8lqNhAD5Tt/viI5cBNKdJODShIGSW/dIe6fXfrXtBCsSetUOd6Ps7gxhYptnI7vIloVR/hh99x5lLMbGd2KJ1yU9RdirUX2fDVoJY5EodxmgQg37tADJbBfr/QdLR0+JNXrU1lMfGYMjmjOsJxdxfNVO3bVCHgw5XK4WQ5JLodRGREIqhL81oFUtqw2R6gZtgF8s0Lv5popJ487NZIvMrgS+gr9aFiel6GMANyWc2rV5tpDp92T5yIjm6tC8mx+82C+QAGUwxKobGNWZAhYD22nplZNAxZTmgTcMhXsbQxDjpI91eRUbELjFLw1REFwSr2TmwrcF7H4cT4NKvXHCWunxCh2GTVecD49eP7rpmh2vUGcI+BF08qVlZsKPEQSei2wrto1YE0J6EAVZLYPqwSOGyTOvRr+Z/JHhpvcR+pKofGiiqUiC272FsbdaNncXW2J0U0PRLjU2vAyQVSVPLkCpaToWD4GIARdN3GTRHllqyaksn+rRTSnahAYdcGN2TCwGg=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"(5) No, only if they're global.  \r\n(6) Sounds like it, assuming you've only got one consumer.  \r\n(7) It's not clear from this description. There should be a straightfoward way to make it work, just like any other initialization code.  \r\n(8) Yes, and yes.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"a10a677c-82fe-3019-bb90-c0abd2c0ef42","date":"2016-08-17T02:20:36Z","timestamp":1471400436,"authorUserId":"disqus:stephen_cleary"},{"_id":"4b64b7ce-ea80-36d3-b127-f11fd0b99134","authorName":"Buggy Squashy","authorEmailEncrypted":"ZBDcLOBbimw7ObJr2o5/o5J7R1rTb81EOgLbHKxSygBUEEfeVXSzZKUTvOnTUDUEjs/ar5itBBqhxOjRvWVX13nMbAYHnPaXC3NQl2OL5q9vaZgOn49/283izKu07k+QYf5LEfpuUvFcTJC/NG0W7pw+wDl8yR4Jo7WZI3zK2XefnO8eyjXcTuwDvWI7yj01+LS2ceWURGgwGtC31MCPkMKTFSpLluS4bQ/uYkFxF4wikVvvXu1Bin2uxF0HDNR4Z9yIqcwq3rp9nU9y+Db7sUC6uZ2SVAQBsDW0CqDylLCEFmzSOaU9whhqVbXXabYPF/kzrc3A6F00shedZUbP/l6CRYGWDcTFdtYmiz+PImEjVHCmwPADdHamVeeIyw112VBOpIt4evyUXzF7BA9tP22CC4Ux1BWxNw1gpMM8L17EYSXnrWKq6vQW/ufExHzLlUulEm1n/Ng7RQtUl1xjFZol7pgdAM5ftNWkudmRdIdDi/u0MHYY1zqD/uQXy0lGkLNnN947phypStz0iDN6pdLjNLQ25YfVPVqfzt/xPpM6SyOGuDQwfBjBy5kvDRhH/fhgKnQV5uI3LE3/QoG/vPhG06rv4Srjf3F320XsY/lCqfs6R2OZgU1ojX2Huz/bgOUA4oljzsFo9M4ChkCggSnNysaqtmRfa5uaMDJrthU=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"OK, got it. Thanks again. I decided to go with the CancellationTokenSource approach. In my \"Run\" method (which is based on your unit test), I loop over all the cases selected by user to be run, and initialize a CancellationTokenSource for each of them to a new CancellationTokenSource(), before proceeding with the Produce/Consume sequence. Next, in my \"Kill\" method I loop over all cases selected by user to be killed, and if I found a CancellationTokenSource corresponding to that case, then I call the Cancel() method on it, otherwise I simply skip over it...with the idea being that if the user selects a few cases to \"Kill\" and then selects the same to \"Run\" immediately after (or vice-versa), the latest effect would take precedence. Hope this is clear and a reasonable approach.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"88d0f722-98e2-35ad-b659-40ac779f2273","date":"2016-08-17T18:39:13Z","timestamp":1471459153,"authorUserId":"disqus:buggysquashy"},{"_id":"88d0f722-98e2-35ad-b659-40ac779f2273","authorName":"Stephen Cleary","authorEmailEncrypted":"KWW2VrgFXPouglBBtf3lQA4xXy1rI5htJRiFJiObewBsR6syB0qkhgXGALF3bm7sGrtJO2DmMXl8+yCaQ1U4/Ly0LMrjRV2SpA/Wfi4TpTdfKypdgDdGbQf9CHiYGhwgweFDW55bp6U2vk+fEhAvvHEtvFCWIt90dBmeIF5GPzyOdC1hJ23wlsCNoHT5qKre7YKqUnhyzEcHr0jAzy5mhO6nPGSBQqytV9eorRrnLl1fjdFEJNgIOVSF6n2ju9+vF3d+3ZDSM4fb5LdhMAKzjjMrnPQuhmC8LnJblgG1twX0ByEaRs0tsI9Hw/zvzTzsvtj1pctoJa37QdB1TpD9dvY2Wa7zGX0afa5yq24WbLh2y5mr6UgemDYXabPP7UrR8/0Zm+UDpxE9ro2hsR5pWXeyL0wHxmQr1m7VuVf2Nss0lv2CITcA+VVU7TmHYTri+a2OWKSfHimj5v0mxm/+h9gW2uvUqnDkBXWsO6K8w6fFhBRYTDiFkZA6PT8oPuoeRejDBhP/tkHK6AeGa+Fgm0rMYa6y+ZdQKtTYJ1CPoF/XEOnidUvr9HiLE/bWmd2IdcXL6L1Q6O2kylAiBdv8E0PLupbCtpxQ54slRPFIhoUgcJTJvPmWNP3BRqStxgGRchod9nsn6T8QnNnYTKiSBAZowR+cq+ZFWuRMUaS0Um0=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"As I said in (2), there's no way to dequeue items (except for processing them, of course). I recommend having a CancellationToken (or some other \"do not process\" flag) along with the item, which your processing can then skip over.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"df045556-b7d1-3bd6-9be9-0606b7ced0fe","date":"2016-08-17T17:25:30Z","timestamp":1471454730,"authorUserId":"disqus:stephen_cleary"},{"_id":"df045556-b7d1-3bd6-9be9-0606b7ced0fe","authorName":"Buggy Squashy","authorEmailEncrypted":"pMnZYssyfJnDLfHkxCjKUxUrP9WPyBdUh6NKXlVIQqjf3TCiJa4hgtKFq9pJafJuWIVm4GaWInCZtisDXx62hMOEWwm/sDtpvRwaqpf0t8Px4luQqurzSRv/wc+qTPYfx03stc78u18r/T6Lky9xyMWC2akPuR6P1Pa79NpytqbUZuU85W2TV00AdF+QFPv0kvh4INuhIqL2Ey+23w87cjQ/grjnzb6L3W6rsCgWPjgPuCBSzwCP4wFbGhFmF9FkTNfZWPEGFpzOgra/b8Ph6kqeXyjU0aRmRJC92wXe2WdZUTW9YRMh/0hd4/jqhGWNb1IO/XBDTHlzlRDtVWLI25W0DGT9FB30boAXsUkCZuds4XuGSbHQoDG8hk0+H9eCQpTSvS2uN3+8G/NEMYtgmSmztx5uzY+w6nc6i1DKX1iifn8hOz82TYE4pZd+KZqroqj9BlDhHmtZJgkFhHdmi0lXZ4S9vQAMS0sr6Gg+IS5CVqIuEAKdM8Y0lvOxC+/w0zgEr2x+1Z0pgQAuf/LZbPkNmQbjKsRAIO+0hnH8r85dcImE3AoexJsVVl3LJowviDtBL1CoRldxlFyUtQkSYCnN17O28LCa3AgPhznyKeiuyxJHhouWkT/vx9oOSgW/UrB6Ocm6i6rJVKcQokpEntaTUJD9XptF2W+olOM718g=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Thanks again, I completed all the implementation, but in my application I would also like to remove some items from the buffer queue (for e.g., if user submitted many cases to run, so that some cases are still waiting in the buffer queue due to the throttle specification, then I'd like to allow users to select some cases to 'dequeue', whereupon those cases should be removed from the buffer if they are waiting - but I don't see any API in BufferBlock to identify a case in the buffer, much less to remove it from the buffer). Appreciate any suggestions you have for that?","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"1f0215a6-23f5-3334-85d4-257c87ff45eb","date":"2016-08-17T17:07:55Z","timestamp":1471453675,"authorUserId":"disqus:buggysquashy"},{"_id":"e1a40902-dfa8-3d2b-a7f0-2081bbc6a956","authorName":"Stephen Cleary","authorEmailEncrypted":"A84dQTxahh5yuqZI/0epTKqu2JxVxELgZSL35EpCcCgnKF6w6t1xbgF6mIVHNXwa+FNeKyPSUXHdfvlzP6RFoWxk+RTQM5sUgqsa/oHtS4stJTQUi7C7vqKxsMy9WD8YRNS09M14NSb/4V3xrfLhczAqDagZyU63u+Mrlg04fCafyMNvvtBCMW8Iu6HmTedaQel4CRKW+Rs8nNEiYfQYbdd52bSxlz9hfyVCN0G7Rr4IDyXpwhSRjHW0mZh1tR4daQIuxFqYHxNXH10icZeBWBUXJWmb45WdYmRT3x60BAWgGkSR27OtodVW/C78c3SMWtDnFMfbKr8WS4NU+RzzFwZL6wgLkn1W7R9HqRotahSXmnmP1mzhE9IJIiv15JSj6DbRK9S7mdiD52ZSB2FxvUqH1OpBuvH2Csnx60pPs0QTMHuEYGJpha/lVj3H3eEfYaS2fmcyImBUYAO4jsyYL2gRgShyAeiJoiox9px040qwZ940FpEfsa4QcrFlG0Q5cWv3BkXYtFuJl3tntJ2GHuBlZWzg5vY1Im+QlSE6CPqxByzKPPgepaYHDLplVe2HjKThMgApu3+hPsuSwVOszo04JpRdMdgJp0arzRp6ICIfDEEXyw29pjzqm1pHxphbr2W1GbhV7v3kw8dc6o+/mViE6O9Mssgy9Z1PIbL73oQ=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"Yes, I believe that sounds good.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"4b64b7ce-ea80-36d3-b127-f11fd0b99134","date":"2016-08-17T18:51:02Z","timestamp":1471459862,"authorUserId":"disqus:stephen_cleary"},{"_id":"02a16955-1167-30ef-a48b-7dc0c47e42b0","authorName":"Buggy Squashy","authorEmailEncrypted":"r0T26wP99BOdIrDHBxvNtiIhiTToZPiUQmczR87Ld7sggUmckXiMH1Xhun9tmAI7JfmSXCWIeFu3YMBKTKY3Lfx8XbRYXX5u8iQn0fZHcvkEXwgu5po6i/3YsdPokOCj9kc607tlJRe+8wnyua4ecv68S5ifKGXl6I8bK8FoqH4kxz6SwHWcDrDlQkunXQ1j6C+AxkwVu9K69H8D3tJT1Y/ss5lthedlS62ErYXUd/mTBfVoyPaGnQdsN2UX+5MpIz797s4JimP3tcbUOcu5rSghtv/TPBnhubnKY47ITDARH74WMkgG0vMqLO47qm0iKoIPNKNf4wAKwzOEOsVOJyv3NyoeDiiS0ZsYBoVU7nNK76JWCNX/LbZeI2b1qJqW7j2Td6WoFKVM8Ao7SoZGiAbrnNMNVAkTa1hizaVC5IzscgOtzU/Mmor9IX3gr6igcJDmKhMHvAYomjxOvtiO4GX7hUJ3lyxp3Cp6EqngaptbTAH0CkNCuav3h2UgH/JToR8HUWgIGDn/01/YF5i3qlKcfJG5fhZn0ILDA0jD9GuJTE+JngVKM9u+mHFaUQCgwFPRa+gPRrrnRE9/yoiamlY/3mIWFvo5xbMROIEoL9LTEFoAZfdDefT438w5fwwayIwE7YUSp4GH0ETf4W7Zx9p6Bl47B9PgG6KxQom1+rY=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Hi Stephen, regarding the above, I guess a couple of more questions. Thanks so much for your patience, and apologies, I accidentally deleted my top level original post/comment, not sure how to re-insert it. Anyway here are my questions, (9) In the Consume method, right after I get the current item from ReceiveAsync() and am ready to process it, supposing there's segments of this processing code which are blocking, is it better to do move these out to some point so they are executed before I even enter the Produce/Consume cycle (e.g., in your test method before I get in the Produce method call? Is there a way to do this between the Produce and Consume calls? (10) For the CancellationTokenSource corresponding to each item, and other such flags or data structures associated with each item, if I initialize them before the call to Produce, then in the Consume method inside the while loop, if my process on each item received is invoked as an awaitable as: bool ok = await my_process(item), and if I check the boolean \"ok\", before populating the CancellationTokenSource or any other other flag or data structure corresponding to the item, then there shouldn't arise any race conditions, am I correct? I'll plan to test these also myself. Thank you.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"e1a40902-dfa8-3d2b-a7f0-2081bbc6a956","date":"2016-08-18T14:49:37Z","timestamp":1471531777,"authorUserId":"disqus:buggysquashy"},{"_id":"24cf38aa-a9c6-383b-96f7-94de4197da9b","authorName":"Stephen Cleary","authorEmailEncrypted":"lBpybe6mH1rwYFFamkb1F1mmngwCQRN6knRQOLs7lW0oVsoSMMtUQw1Ud5ZvIo5MmQdFXXGwqul6jmrio5Qvf82hOmF9YisWr6xFvoNXZERZoEsDVg4bxMkIptNEgH+aw9ytp7OPYl6xie4eoTop91SxvW/ueNO46QCFnrHmVzgIwG3/d4zhRQ/+aQOeWlKJVgMTckAMunmHoAk/xeD3Aocqqo6rjTpyG3xHnRBGURoyCU2WChJbvk2XIJ3x+KnBqKGYlXb5Phz1OciBvYtPWThJBPY/V3iyNY2k9b7L4XDYjxojhQnMhJ4EOjx9naZ3pzfHwBAPdwbrBXBUad/A2PvIezXrOdD2jBjwBm1S/gProi/AUhEzAfOsNlPUtx8i3oDxtXCN4xSKDNcN2LzXXnuBXzFQNIXX3m519xC3b4/M1Ke/6N+Ac3AcXdufpysV5VRCs7Uvky/n5QszMQGnylF9cTGJYaPCWuTBqUmWRA3pUzAVO57JDopoPtBBUl8Mt99AqXcoEFj/L3ofybz8deNcwpToR2t2OUjJ4HqIUugpdIwerLtEsFfN+8GmcFPpmuvmj+9Ou4rn5XmaOnsVn0ezjU5rWCtb1aizppmtMjRT0FzecZbpbEltomVSSizLy6YVpYYVlFLMRKB5uJWutvPlZC2bQVQz5/9QCgvxeQQ=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"(9) If it's a separate step in the processing, consider using a TransformBlock. (10) There will be race conditions between issuing a cancel signal and the processing seeing it - this is unavoidable. But it is a benign race condition; it will just cause a small amount of extra work.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"02a16955-1167-30ef-a48b-7dc0c47e42b0","date":"2016-08-20T00:47:32Z","timestamp":1471654052,"authorUserId":"disqus:stephen_cleary"},{"_id":"6f51f1e4-4ed7-3083-af13-f118de7f6187","authorName":"Buggy Squashy","authorEmailEncrypted":"QFcQx8JEDJtgknJNFcZeU/kLbRoIpwVEToocdAyb9FlMN0FSyr7ltOsIcVqzFGLfZfqfn5dhJiRwMuGkhy13pBfoMvCcpCGgJ/H+l6ZeGpNX4hMzAZTpa51kRMY/M78wqUNCdE6ARScDKRRk9IVakGHD8S398+U1ZAhs5sQ94AXEgnPe57dczHc6tEBqek4Yq+Iyl77zVq7HNLjXuwasJ3uQHh6AvJbXC4x9blIm/eMiv/Kgwbl1clEVj5mKuH4YA636qHwTBXWyQpIs6xpavtl5Jud9DRSisZLdILVUjV8B7VqztuUrKJY/KIn74vFnZJEqefv6mIkWKE4lg9XSE9spf8O5CEXUe7ysygaaVliMUXBAy2ESN8sTv2Ksssxu+5AoG9WBjDxAJHkrbHeRKBTvNXv0BiYwyENQPYvLt6pv0xw/2/uBqFAXpscBO63NPmN1wiQPtVdL6Iy1Yp2HnRoHSnZ4CQtXfk2d2XCZcOZaoOx1wOzwfSuEOant9Z6obeYBXHgviAMlc10DDUd73RfeI5lP7Ksbd62gw+RckdQSNqWXCAEsKociQtjQmSgPGL6EUnR2QqpRnrvC0HjLiE04jPzQ71TK0E/DZxB3mgaq56KEMKOrU1qi2W9/4T0esRTeGHJj2lXvtFc7c7oihCsWSs4HxFOO8iL6HZWHZEQ=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Hi Stephen, me again. Thanks for your patience. I have a couple of more questions. (11) First the producer/consumer queue implementation appears to work OK for me, but I noticed after doing one pass on the items, then selecting the same cases and attempting to run them again does nothing at all, any idea why that might happen? From my limited understanding it appears to be happening because the buffer block is transitioned to Complete state. Can I reset the buffer block somehow in my method which is analog to your test? Or is this is a use case for multiple producers? Even that doesn't quite meet my requirement it seems. Can I just use your first example for single producer/consumer with throttling, and just drop the call to queue.Complete() in the Producer and likewise the queue.Completion argument in the Task.WaitAll(...) call in the method analogous to your test? (12) I noticed that using the producer consumer queue enables the cases selected to be run asynchronously from the main thread in non-blocking fashion, but sequentially one after another w.r.t each other, i.e., the first case runs first, then the next after the first completes, and so on... this appears counter-intuitive, I thought all the cases could run non-blocking and concurrently since once an item is received, it should be ready for processing right away? Perhaps it has something to do with the fact that I'm using one boolean variable (initialized outside the while loop to true) to await all the tasks resulting from processing each item. But declaring and initializing the Boolean variable inside the while scope still results in the same observation!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"24cf38aa-a9c6-383b-96f7-94de4197da9b","date":"2016-08-23T14:33:14Z","timestamp":1471962794,"authorUserId":"disqus:buggysquashy"},{"_id":"038e1ac9-6cce-39ff-a744-7bf625edb351","authorName":"Buggy Squashy","authorEmailEncrypted":"WhhehmeZOCD03Itwhxz3fa/3Dp6Z1ZrKK/XlMMlpAJZGLGCO30GpU0PN+KQv1bacOB5bEiykYu1BLsp5PUKbKKO6Kr8iHbtwHYctko6SeNQNcE3L3Bbz+/K1iwswDgCSOgp3kPIEt4G2brbBKinywEraLh463GS+gdiP/JvBVdRfQPDc86lJyiM1fsMlP1mYJhGlyooa6oxhY7DbCSCe6MyjkHKqhkZVHSTzhjSWK/aQVdhgHSkf1OXjhmuzZjQQw/4pD9xDjf+4cLPzMyG8Fa9UyR/lK1Mp3+CKyT48plp7/lSGaJ1doDxxyUccEGr7p6/O3WTWGIDvvyrTokXEBaJDC/uvc82VLywc8LukQonpNhtweMfn70zazfSJLWGI04m0mUEQ1zb3AfBGdD3buKstPF2PudE1+rVYrWi0FlrTWyq1GNdMwihaWixVqcfoFthnSwPwRpJh6I2/bogy3+lkpNauMDsYqsT/kYLhDRuI4VJIQCvhWxOJbhZtYICxo0V1Kc+SWOgJ1FfGC3UMBBoDYWbiw5W+pRTgBHHAVkummY9qktVvRA95ihAAZDn952gLsLaUicvPta1jEbhzXwwhZCX9x+7TBahXTF8F0UrLhWVH4v3rkeqHKP8f22pm54miF2WvedRS0BzKXybK5hNLYQYAAHuHRkOk0TeKVAM=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"For (12) I'm not sure I followed, I checked the DataflowBlockOptions definition at [https://msdn.microsoft.com/en-us/library/system.threading.tasks.dataflow.dataflowblockoptions(v=vs.110).aspx](https://msdn.microsoft.com/en-us/library/system.threading.tasks.dataflow.dataflowblockoptions(v=vs.110).aspx) and it looks like isn't any property called 'MaxDegreeOfParallelism'. Or did you mean 'BoundedCapacity' like in your initializer example for throttling? I already am using BoundedCapacity but I noticed the jobs are running asynchronously (not blocking main thread) but sequentially w.r.t to each other (not always though, sometimes if I re-run them I notice that some of them randomly run concurrently).... I am confused here.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"c4dd915d-24ba-34e2-bef3-b4747bbdd262","date":"2016-08-24T21:06:59Z","timestamp":1472072819,"authorUserId":"disqus:buggysquashy"},{"_id":"c4dd915d-24ba-34e2-bef3-b4747bbdd262","authorName":"Stephen Cleary","authorEmailEncrypted":"D60bQ/tlObvvJ9rxg2OzrcOOaOlWpOtBhuMnjif64rJOHide3UGJcRBpGdTprBFjpuWE0zye3k26oNizEuG8ALbNJO0AkOY0iLE/cAN8y1OSnsXvl+pisD8WnbELwGy6GGcCuyFZbFcEBM8EYY+FaRDmovE1/8JWrub1Q3NUZZ+6uKK38O3Kc+VlWiiizyomQ7PQnuJYhHY/jxnQ0K5c3paEbfYlPuU6qIlghhGGyBF6FbbmXZx/pP1C22rp2a5B/9rfEO3qsxpKhCPVfHyPuKgU2ZT+X3b3Rg6sp1BOP82BIMgfG/+yA+g/Fv1lo7JE6gQRa239sQ1rTWmc65JtyrwPJEFFr6tLPe7akUX7pB3Z9FbWeAVwqEwsjrhGZHY97ZNNgXKFJpjDq3/718tW3o2aiSI6Av2vHOber7zpEZ5A7pRFfKc8ixnMuZFwXRZRfjH2p7Dz4pzLnHc3uv++q3wQtfPK1mSh5zaowq0cJcOYkJ3FxKDhRs+A+hE8NjWoEDtf5bkDpSJ7LIoF1N/Soh6cgptYsqJeb5eueAW+u6JW0IHvF5E7lHdpPZRoTioH0jrRRkgPaKcYx4W1XpCeUCq7FYTsgtvNmWKmeEI+uAid7oZDThBaqSMQD1b0RqET7wUHrjvXd4GXacXbdM18Y4k+cEo4LhS/8qhLI1CTmpU=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"Right, once a queue is completed, it's completely done and you'd have to create a new one before using it.\r\n\r\nThe dataflow block should honor MaxDegreeOfParallelism to run concurrently.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"f344cd77-d003-3f25-aa06-ff5831438d89","date":"2016-08-24T20:21:13Z","timestamp":1472070073,"authorUserId":"disqus:stephen_cleary"},{"_id":"f344cd77-d003-3f25-aa06-ff5831438d89","authorName":"Buggy Squashy","authorEmailEncrypted":"B1uMYnaskmt+zLBDj14OEwPgYmxnPUBXmv00gx2Iz3bhcut+rfAdDdPVpNjFzZf3C/J6Qv3J0PFM+IrZXJ55UqcV79xZ/lcgSUvyAQAQdaS8M5CK61fAbSqDEATesdMfKXW7O2A+PpqICq8XspPXqxNjVjMo9HXNT4ZM/2dDfouRiBngknncl62/1U+un4Erl5YHr23t36VWzynZNHxBp8AqWG5CwzyqVA/KvOJrKL2zqDKpcBzwLJmVYZx2KLCHf4VYUFJo35sGpWGuOMJN0l+yUAOL+zU83JgxGwkgyBXytjpsp5lDDsqk+jfhDhRVhub71TMasR+ud+5ji/J7AhKbZ5FkEpFJKye4SLcteeUKtyMdm3ShYdeKB/9meNRkyd7KVhNjpfyKEa0PkrjGdvp/o5YrdzjTF7kBJymJpGZa6nMwWQDDG/f6OOn2Uejh/BgpfJ7sZASWANM5JrezMnYYufBE52hFkrpMkU+i2trtiLesO4hYeunCZnGYM5pa4N6rm9Zxfbja7jpcAiUECGoemzheRLJgEm7KTUcGZQqsYWM3LychkcuU7vTrtAZ795afTuooVOj89uTwT4Jt9UpTBU2UhOdlO3KrU5PHBhfEzXMd9LN9HYGQeG/Vst340xJ693Bz1Dmaw4JLgaCG+3ABFkDdhHgyA3Bflzn0/5c=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Thanks for your patience Stephen. I posted another couple of questions but it disappeared. I think I resolved one of them (11) when I re-select the same items and submit again - nothing happens. This appears to be because the queue was completed and so I tested that removing the call to Complete and the queue.Completion parameter in the WaitAll fixes this without any apparent side effects so far, although I'm not sure if it is a good idea. (12) The items are processed asynchronously (non-blocking w.r.t the Main thread), which is as we expect, but they don't always appear to process concurrently; more often than not they appear to be processed sequentially w.r.t one another... is there a way to force them to process concurrently as well?","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"24cf38aa-a9c6-383b-96f7-94de4197da9b","date":"2016-08-24T15:56:39Z","timestamp":1472054199,"authorUserId":"disqus:buggysquashy"},{"_id":"8c49be6b-7e51-36cc-9095-e5ed0fc6529a","authorName":"Stephen Cleary","authorEmailEncrypted":"mOsVWa642BnoTcDIQ8ePLVJ+QJimWZezSakSBMn1L4jFDqeVBViUDrw0I3gzFvUBahx62r79bNfJHwYwHTf3zcRIY3zhpW0Ct4sVQyin4fvr8NMExZkmrMugGKBzFJ1os/kGKuvV/pKOYnCXaZygtSQmnG39oB5bTVO94amfiGunUw3NCpUazfs8URwy8xu6rhE3y3+/ageQz9L9Z0PGF5pjv+hfJ2PRPQHNGAT/OYa1oHZtPNphzJuGHMOg1qWZ7+Pe4om2LeYpelDe96uzGTL4rEc5I5x3ZutFwDPf03nAE8GlA3HwxXnj8zqh+hhPp+p4ctawpArI9o032IuYe+NYbmD3fR4ZKy5fLzAUkHKT6clh+2e9grHBLkEuUXxe2rvA3u42MUN8A5jJXaIi4zqHdKoRfy2LhtD+vcLbjM0N69AcPutJtgFaqZpxDonDpr2Eqm4I9c5VA0wPtUY/7Acp8S50u+1BT4bIrZCyWfjUpOicIAuCYD+jN2w6jgpz+TQ95fscrUWvdYw5uBQoblFDlfJPXgyFGHVNLlpbfbPGyyBj1eH1i10QKklf302Si6Krxj/kW1m43fnbwDHEASYZTERaLf2UijCHr6sE0TeiPHfq5uGXz99RHmyZNqY5n6sa0qKkJq75nkaBbiMmtp3l+3Wq5JoKg0zMRGJwcHY=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"MaxDegreeOfParallelism only applies to blocks that spin up processing tasks. Check out ExecutionDataflowBlockOptions.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"038e1ac9-6cce-39ff-a744-7bf625edb351","date":"2016-08-25T02:23:02Z","timestamp":1472091782,"authorUserId":"disqus:stephen_cleary"},{"_id":"da442b6c-3580-3513-ac90-5be383fdb609","authorName":"Buggy Squashy","authorEmailEncrypted":"aBeeXU6EjcFKI1sFUXKlrWz2T2+R9I/TFNWOtP6kbxoYERmPiJHSAsRYR3PMO8D46+2ep56BjYhv3RahNF9V/2VrxVf7AylmVUZFUg1pdSq4zWWQAzk0SaqAMvJIISlt6RvhN5sCvZW7k1ZLaKUMrrnAVXKqkPyj2XPAM/R83h8V20uHpXJYuopAp2wpuFScP4GLl0jCXnmtMgu+XjJ6dSz4bDcbd5CYB3HfvAKMfVl87WqovddqZcD8p8YqcXh7j+Qhw/UcB7pYQ17bAytuUM/qwBgMR1l4tkiPZ3fPDJRaWdQNX5evUoYa25WdS2LNEn0D+ChgZYTpyKzL6sK+a8YxjoWV40BvSmcc2oygQdePmpUgVA2yceybsPsiqBYLKzp/fAyZ6ZT8xR7o34wG7Csj+UhKRL/TVier1eliVg5c+vPjxMxfFk7L9XTU57XubvFKaH8VduM8cGgQAJpXk0zXn+Y7xwyvCRSjQrDcCUKXLLFU9VnVDnbcvae8iL7xltzwwRXmXleGcoARbcrc1rUoFcOftZEtPUZpLBNvSCXBMKBTcxhuQK6OGuEcpaxvkjJkIvMshCELN5aMVMvOIn31dbkG8PEBPvwnr6PeXCiFkZiS7ttEYcI/EWaR4DmNRX77Re2fTX+H7qy/O3qN3+eYYCd6MMDMvQkpQBSKjnM=","authorEmailMD5":"b13725d59b683df333736b9a404801df","message":"Thanks Stephen. I tried with BufferBlock initializing it as:   \r\nnew BufferBlock<item>(new ExecutionDataflowBlockOptions { BoundedCapacity = maxCapacity, maxDegreeOfParallelism = maxDegreeOfParallelism,}) with both parameters set to 8 with the rest of the code as I had it before; but I still see the same behavior, i.e. sequential processing of the items in the block. From doing further research on this it looks like BufferBlock is just not designed for this. I tried to re-write my code using ActionBlock which apparently supports concurrent processing and throttling but no luck there as well. I posted it on SO here: [http://stackoverflow.com/questions/39150903/concurrent-parallel-job-processing-with-throttling-using-actionblock-in-tpl-data](http://stackoverflow.com/questions/39150903/concurrent-parallel-job-processing-with-throttling-using-actionblock-in-tpl-data) ","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"8c49be6b-7e51-36cc-9095-e5ed0fc6529a","date":"2016-08-25T15:00:51Z","timestamp":1472137251,"authorUserId":"disqus:buggysquashy"},{"_id":"8e83b8b9-1893-3b43-ba8e-1a8c05947a86","authorName":"Nicholas","authorEmailEncrypted":"ofuh6t3vioo9kVVWmVcgJWdR0MfmNX6hZoU6JWf0otwQ5izBNNx25+F/ZHMuN+Bd7YbN1vSN6WZBxH7IFGp0fDWjQxZJOm/H4H741edeqPrkaeGyODbaxLCtouJqGF6LZY6nPdAf1Lk9Tj/Ltgg+HR8v2+aPx/1n7gZ0kpXDhS3QGeLpKa1o450g8zwnHyyNT84ZntmZ9Z+7Kw+9F1j8OYtizOitEbdi9bXuZPqAb9Dy3bxdH+bNEQW38CYqONv+uEc+Vf46NmKiA71cvpzuMWMYjpupEmR5jHWPof6LD8+5sJUHRS9UAOXGZQll7xOIne5w4K4s7x/5njIPv5HNgmbByjve1KIvrbUbCc/xKrU3j5+sbicDfxUb4k38oYiSFx0neD7v//JmgEb8MLM1Hk44YUOp5CRZMMZiabrrvho8bbKVQtqGcjc7mkDSNKatGk2wbYZ8tYRTZwLgsnxpeFGkzJ7qJ3kQGrfzv4IojXHPpuhJO7QrdSFMoCD+JgKxippDHbVbTBSQ7pYderEAPXLlwuuCt1MFO9Ye+qWjTf6mCztBkRUi3Ub+Yq93iz3Bwhp7oV/XmakSsbAE5VdT0LrgpBhXHV1SmAUas7l9/yuG0eoV+/maUENwD6fFCrs6ziIuOdp+Vi3llYQHxwo8Qp7bo8DzMz1ugtla2t4lNB4=","authorEmailMD5":"a495a370830f1691666642f1e0fd5ee0","message":"Hi Stephen, thanks for taking the time to explain TPL, I think it will be suitable for creating a pipeline for processing throttled tasks, e.g. only consume xx per duration. I guess either in a specialised producer or a DataTranslation block to release tasks as soon as the duration has elapsed. Putting it in a consumer action block would loose the parallel execution. Do you have any suggestions?\r\n\r\nOh, the last example is more helpful if you used the following consumer definitions\r\n\r\n var consumer1 = new ActionBlock<int>(val => {  \r\n results1.Add(val);  \r\n Console.WriteLine($\"1 consumed: {val}\");  \r\n }, consumerOptions);  \r\n var consumer2 = new ActionBlock<int>(val => {  \r\n results2.Add(val);  \r\n Console.WriteLine($\"2 consumed: {val}\");  \r\n }, consumerOptions);  \r\n var consumer3 = new ActionBlock<int>(val => {  \r\n results3.Add(val);  \r\n Console.WriteLine($\"3 consumed: {val}\");  \r\n }, consumerOptions);","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2016-10-04T13:25:24Z","timestamp":1475587524,"authorUserId":"disqus:disqus_7SSc9LmSyX"},{"_id":"e38a5c27-7a09-3773-adfb-3d3b765cf902","authorName":"Stephen Cleary","authorEmailEncrypted":"fkt2FIX6pmCZkltw1TIy30ZodcNSLagu+3QLhWwmfp9oPjVLMHFrTNo2ToKgxtDXyON2iXWpXrIvhrLH/y7/WqAI24GZcJjbxr/KVfCoYi8c1RYm6GOwyT1gaHGxRQFJbzKuZsjobBaSPEP4EW0PR/eSoPb4ygiuDndYoVxdNiS3vI1oEcqB5sxaPUizJL9DQWm/Z8K9j8W9P5p4iXdBJZDqY8XXJm18dwHJquOLboxXfO6UB65hiDQ1ZttPj42KdjEutPbFRRKSmYy4eNNUG2sY0HDzciCcwvSMwjI+A6T3mySERxsdyybJY+FEtp+hJbVTsrPokw3W9zOO+1B3av4OqRQPUZfizoxg1HrpBBm9pOXSoW7WTIOLt4p5ybLhW5yVlsBE5HZE52O9hCco1UqrV4GfsOxZa3q8hWverjfd06tqvQ2XKt6qW0rwlodcu94m0OKJnms46ISDiw5BulXHD3ukY7sedR+y1fRiXyfnGzwJuJJVvVL7DDh2+igoIxBUJyO83jkVsSLYHsRbVrIoUyhnWJeAd8FO0/f826gACmbreut4n2hTwG4IR5eFAj3+pcRSlVaFHJHuSFWXNcFAli/fhuEpc2fvasfnBaIVaUCiQ5YiCD3bONYFGMOhXtKEjhKRs90205s8o0PyawAhQp9bRojtVY4/voEUxss=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"Hello, Nicholas,\r\n\r\nI do not recommend using TPL Dataflow for throttling by time. TPL Dataflow is designed to always flow data through as quickly as possible. (The \"throttling\" in TPL Dataflow is more of a \"don't process more than these *at the same time*\", not \"over a period of time\").\r\n\r\nFor time-related operations, I recommend using System.Reactive. Rx has a number of built-in throttling systems that work with time durations.\r\n\r\nAnd as a bonus, TPL Datafow and System.Reactive plug in well to each other!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"8e83b8b9-1893-3b43-ba8e-1a8c05947a86","date":"2016-10-04T17:11:08Z","timestamp":1475601068,"authorUserId":"disqus:stephen_cleary"},{"_id":"1bcea007-e335-3ebd-b122-4d7b40783a0a","authorName":"Nicholas","authorEmailEncrypted":"joWsRqByx66OmQKgxwjTSVa/RUo07ewWn83YWIA+PMf2dpQVHxeDhibEMD8uAuVBz8GTAu6hEEZeeaJL1otmMcLZz447f1YxFVrDRSpVrL8qX6XWtxeeadSWK//pRSPZYPvejn8YJSteifHqFSuU8c3JYbOltCEwK7ClmGbF6IH+A1gsvKMUlctl6CPOS0dPYE+m/lbMN7apDuVdIlTNJBfjhrtuXMJ0hMHWvy9Bw3s0ETVqL3wYUMW7s4WAIzaqKD4R/ZdN+x7dg83jELKd2/YuvsQpxFy7orTPXf4VSGaEkRu3JwjPkwKmDhI6Lfkz6OZzwi8pYLoswndbMCW1PuWSudWllNA9BkAucBaiuq2JjfRSYwCR7TmBGh+1SWwYe2z2rIZu67FLwLLo5Sx6sp91X+RX+XHAjgNXn9HE01XAXfUiGtNkr6fT4TSWpteQg/t+oO4ZnCa3jbKSX4XjY5p4zgNuKbBHn1ewpWp6YZLixvtTyuK8Yu8onRfMf0wYoyrZihnk1YtlnOY5COAyFQJHT22G1b/xvWxSFbZjtMfycqX86qKeznHOdYAzoh97uZP+M14607IsBrIYlgSeSNGOg03I1Ikz/dDvQfBiNLm2NjVTMXKQt/ENBzt/mpNyol/iMkFaHhk7nSpYqTz1469Th3a62biiJkkNGJb6XMI=","authorEmailMD5":"a495a370830f1691666642f1e0fd5ee0","message":"Thanks for the reply Stephen. I just extended your example with a Transformation Block that uses a semaphoreslim to waitasync after xx items are processed, it then awaits a Task Delay for a duration with a continuation that releases the semaphore. I think it works for now, but I do not like using the wrong tool. I am hesitant to post on SO as there are hundreds of similar questions, just need a simple async queue that I can continue posting tasks for completion and it will manage batching the execution and responses to the producers. Maybe I should take a look at your Async Library. :-)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"e38a5c27-7a09-3773-adfb-3d3b765cf902","date":"2016-10-05T02:59:38Z","timestamp":1475636378,"authorUserId":"disqus:disqus_7SSc9LmSyX"},{"_id":"389f005a-be32-305c-ab95-cd4edc9be21c","authorName":"Peter","authorEmailEncrypted":"CPkdZNfjciDLYS/VChsbQ+zQgQC73XKCoXc8QJEv9ikTUB+T8L6t7qMTZuqIEzrRZwipGeUQ+AJbCZJsyaxC8uJp2lgBd2n/NDoLu028OiIcZmLuy8RUwE1ByGFkZEs6xEW6XUOHOX4OycFCf2/SanrpFQWNY8+MbsiL0/UTGA5nTvy5N83bmo5QEfLKnFFv+PstoZ/HcS7LMCqD26FxEnFSejXFiNA1cuIpImaUeE+AF2a+GlA5B0yT05hF11P6ztXaJBnli6YqkQk6TWXZuMkv8EEhIKdWEXWEVsOiIZxkHYC8Wk6p36q7Pnb+mcRFcrsOsTA7frZowWx0+6aHC6jyA6Mqfvk5oRlolBdrqoHCYYqsEbEswjGOpznoYrRRLxX8mHaNsZVSgmg7dX37TlGdZH+OlzbKJmFjl6V1iEw65oe6E1gQQghpd3zYty5jEHuA+ZVtVZM/n6r9mWLmqig7GX9BlArsGglhZ2qv5nZzyUL+n2ZxPcJYFIWekCTjiXkMDeFN/9YtZECAoL+8r9/nusHQsOyjye7xYnWs7AP71SPEW1BAHkMr5SGtZnCg6/iDqJzdRnY0WeH07Ipc70o3RyfLxXRApRc/t0l4G+EOUp2rat7/5fn/tZMuzmszdTclobq1Jl+zlsSw0I8nrjOyEZqA5OOiciE63aaO2lY=","authorEmailMD5":"c4cfe03de383452ad0c9c586cf12a4d9","message":"Hey Stephen, not sure if you still respond here but i will give it a try :-)\r\n\r\nI started working on a program and thus exploring new things .NET has to offer, so i came across TPL Dataflow. Thanks for explaining it first of all, but im kinda at a point, where i probably don't see the possibilites i have quite yet and so i can't come up with an own solution.\r\n\r\nThis is what the program should do:\r\n\r\nI want to import XML files to the database. The incoming XML needs to be parsed and validated according to the XML schema. After that business objects need to be created and it needs to be checked if the item referenced in the XML is currently locked by a different user/process. If this is not the case, the business objects need to undergo a few plausibility checks and if those are passed, the data only needs to be saved to the database. If somebody is currently locking the item, it needs to wait until the item is released, so it can be processed.\r\n\r\n- It is required that each incoming file gets processed at some point; it should never be canceled or require that the same XML needs to be sent again to my import.  \r\n- The order of each XML is vital and should always be kept.\r\n\r\nAfter some research and many tutorials like yours i came up with the idea to use the .NET FileSystemWatcher in order to get notified when new XML files are available. This process (the producer) should create a joblike object for this xml file and and place it in a BufferBlock<job>.\r\n\r\nAn async consumer would be already waiting (blocking thread; async/await; while(await Source.OutputAvailableAsync()) for new jobs and start processing once the first job comes in. This part would parse the XML file, check if the syntax is fine and validate it against it's schema, create business objects out of the contents and add those business objects to the job and place this job in a different BufferBlock, where all jobs gonna be that need to be imported.\r\n\r\nA second consumer would work just like the first and await the first Job already and start by checking if this item is currently locked. If this is not the case some plausibility checks need to happen and the import into the database can start. Job done. However, if there is a lock on this item right now, i would have added the Job to a third BufferBlock/Consumer, that only has the task to poll and check if the item is available again and place it back in the second BufferBlock, so the import can be started (the lock will be checked again to make sure the item is available right before the import starts, in case we had to work on more jobs before this job came back from the polling-consumer and somebody locked it again).\r\n\r\nThis in theory should work quite nice already. However, i have one more problem, which is the order of the incoming XML files. In a case where two files come in referencing the same item, whereas the first will be placed into the third BufferBlock (lockcheck) the second XML could be imported just because of bad timing where the item gets released after the first XML was placed in the lockcheck-BufferBlock. The idea was to check if there is already a job for the same item and also place the second XML in the third BufferBlock so i can keep the order. As far as i am aware, i have no possibility to check the content of the third BufferBlock when processing the Job in the second Consumer.\r\n\r\nHope thats kinda understandable. Im a bit overwhelmed with the TPL Dataflow and kinda can't the see whole thing to understand what i need to do :-)\r\n\r\nThanks in advance!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2016-12-14T14:00:30Z","timestamp":1481724030,"authorUserId":"disqus:disqus_hLG8Vpfw7A"},{"_id":"4786a8b0-e1a6-31ea-8a81-7105e16f9659","authorName":"Stephen Cleary","authorEmailEncrypted":"Bfr2KvD+OpI8c7NMxNq44eM3zlcEjERfSCwHNYGh3cHLF4m/0pshTzHsmHPErF1rPzf3iCnGGRaP3ID+oujn1yz8pHpqe8Mhf2YoCj0Wojs1qRayOBFFATPNR3/m30bkB7Z6745dFwK/ln5IEW6AFUKRXYmZsSgceL4FCxs7mJqha5Z+rjWj1GddfKqqKkTJwTrBlBmCPWYIVC94x2LJ9E8y6ybfES1ikcF9G+I1bVaNc1MSZmRAvuE4M5vZvIqWn1wAuybDCtLuVrCZQqZawPUJZngr/2DGKSG0tMFDO7MfOGl6afs6EZIAMENjJd3ud8ltaQRCvlFMmJUcw2VKw4fKd3dVQaZ/I7bhqhIsqI8XkcsQCNAUy2HdfpIZcxmP8R6fQGkAioHOkeerUDNsdWvaYq3QkAtt8LF3dQRG83MKbqIQctXzjhPbRmoRyqVlN1e1k6jL2RFM2Omy1SaAAbpCcDhIt+rY5KHemsGmExUCTjhRDvYDjgg91SpHA0TdOTPUuxxTC4zQDFsjqSwmJh17nRMVFuGPiOcxZ/lvePyjexjM0sBeZcfv9zoFF4c9WRUWN57E+vZx0Sxk0ZbxN3BXrVHt5jjjxR+inhTiVuA0Rgo6vDsRb2u0HjzKvBU10FnCTEprukcGuLA28dQxd0m2zGkpABIvceGd8Vvn5Bw=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"This post is about using BufferBlock as a Producer/Consumer Queue. It sounds like your scenario may work better as a Dataflow-based solution instead of just using it as a queue. With TPL Dataflow, a \"consumer\" often isn't necessary; you can just end the pipeline with an ActionBlock instead. You can also use TransformBlock to modify the data as it \"flows\"  \r\nthrough. This seems to be to be more in line with your needs than having multiple producer/consumer queues.\r\n\r\nI'd also recommend not to place \"locked\" jobs into a separate buffer. Since you need to retain order, your processing action should just wait for the lock to be free directly.\r\n\r\nHope this helps!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"389f005a-be32-305c-ab95-cd4edc9be21c","date":"2016-12-17T13:38:15Z","timestamp":1481981895,"authorUserId":"disqus:stephen_cleary"},{"_id":"6f6c48d6-ee0a-3759-a404-5729414e8bfb","authorName":"Peter","authorEmailEncrypted":"dXG3E07zk8DX/ui2OhOdAYSwOgZe+cMC674mFc3RdV3JRElIwZh5DBlYO2yqHmvhicn9B96xFpp1gK5+KuqVMFYsyqyS35q7nT30QyRjdVgP/YG8+RqDiQ+uwPi/asjVdUKnYBocWiuFRwkSd87t4juvOSWheeV0K8YCO4bhCJeSPlYLgvN2ezT+EJHuTnta2IJOMfXgH4i6TkFnsMge642ITb7AJhpr+/S65NgVTETyyN5O8P85UiK+IIXeh07+19TiC4QCFeIjF927K09sHxp2/aqoV6SbAAk2G4uuC64MPIoqERP1CRkgCTR9/1Do0NjLyHKOehsXqF1HF8Y6XVSrOI5qpftJ4uV8xbogbd5GsYu0ggKaT37SZdSZICrlcXPQ8TEq54eZK4SetNzL7Sea6SfyBSgVbkY5d6P33v1B3uTlphIPV+PffqpwVZdHi4JqX9bkRb3h2pM16ujAY4kj0ZVVnEhHZaUkbnnBItchngoJ/sEgQD7PsFl+1swOYCFhYj2tzpVCxa+IDm+9OTiz+LDHKrUK54xro5ddv2X+H6I0c83MiCt+bfarr9Y/OjF1yK8eeiqFG1xvvHwSZeD5KUZVTUX0tXVg7BflxQaz188AHoHTjUQ/Hc9ixt0MpGeFnn18ZccOLDJHox3tygd1KfttHDVLQzfAoakLUnI=","authorEmailMD5":"c4cfe03de383452ad0c9c586cf12a4d9","message":"Thanks for the answer Stephen! I'm not quite sure if i know what you mean by a dataflow-based solution? So tpl dataflow is not really meant for advanced transformation/processing of the data? More like targeting simple data?\r\n\r\nThe idea behind that producer/consumer in a pipeline, was to split up logically different parts so they can run parallel, since reading of XML's f.e. can take a while, but also importing the data into the database.\r\n\r\nOrdered your book, should be here tomorrow - so i can get a better inside look into TPL dataflow.\r\n\r\nWaiting for the lock is probably a no go, since this can take hours even. I only need to retain order within those jobs that reference the same item, not all of them, which makes it slightly easier.\r\n\r\nThanks for your help!","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"4786a8b0-e1a6-31ea-8a81-7105e16f9659","date":"2016-12-19T13:21:14Z","timestamp":1482153674,"authorUserId":"disqus:disqus_hLG8Vpfw7A"},{"_id":"d603e332-98a0-34a6-bb52-14358642271e","authorName":"Stephen Cleary","authorEmailEncrypted":"C4lMdi3sThoA+qOL3hevrt1DQxn08HycORReU/GCTkKvFMhKuKFXS5bQc04XyPal2k5n7ipBxdPJObX7SfQKotaUXSqM0noYpAeNcVRjzxepadgPqZqncGp6mRd4wcERNh3Ed0DZqU8MyW0WOLmq4k0s029lfgBhaB+iHxGSa+uHwN190ja8FB3uSTJU6eXG3WOJEXF/mRe4/HBkSAGI5JbAMk0ZGQVIssPSipj9MwKgr7hPgfkMYhhqMcamcJqImQ1JwRpiFdWKlFiAq3EC+xejfoT4i/3Ap7YxD0jnD9LBhgzZeYimMVQoW6z57kpeChFqySUqGkk7Rw4YjZaOXtf6sgQtNOlj7SH7qZB0D5TsRWNc7ODk2qUGGPdo55ZNto1JcejUf0veLW6bMFeR/5mt0zDU81hKQM8HSbi+ARSRm69bZ1/HqZnauzJHsftX7F3GDEuAaBhiW8C8J7CMwgHxF1WbLA9pksgcyvWoobrg+n/8MuDOILWFOZ+jnwakRaxFw+9LsjOLSyZdOuoS42AkPExlmcWog/T2RxaINKT46vU8ztLwKsU4kj+gkdnd26d4T7OyqadN1B9mHRyKp0ohbZJtAwpYAa9+VVlBAUXtwNJkLjQTNL8WxuW0ic6Ves2WowRTbvLnkhScM6n2rNHqpJyFwA8vjKD4ju2K5WI=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"What I meant re TPL Dataflow is that it *can* be used just as a queue, like I do in this blog post. But it's far more capable than that - look into ActionBlock and TransformBlock to build more dataflow-oriented solutions.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"6f6c48d6-ee0a-3759-a404-5729414e8bfb","date":"2016-12-19T17:10:59Z","timestamp":1482167459,"authorUserId":"disqus:stephen_cleary"},{"_id":"4d68b825-80a7-3ff6-bc83-8af23fa7078f","authorName":"Stephen Cleary","authorEmailEncrypted":"pe111dzZHHud5aIz3I/V1/dMnCjz32PDBZNfzvVWe/tXcVRy4y9J4NnbDI2Xg2EKIBt6NGo5E4toCVDCBwzst7ffJw4bXBzi4fWLehTw+9nDsLVdVFRSQJociC6Bi914eBWm4qoTiC1h9/C+Ga5Mxv7lzjSIBa5zrUqZ7Oou/D0WKzdC3h2PgRYs++xNtjmxNvO33Q39dqHxqn1bR1TfVU/pCcDF59F4WUZpOmBCG9DeNyPumjq+2QEwas7LYqZBu6rW36Z+nxgaxMVFR8Kd7f9ZCQBRmdn+fnUvjMPPwhVX14SBQD2hyJDGIQLzAI07UXOMbbp/Pd1MOL2CZcbzmM8iMHtNFFNwBM1RvNgSfavtRqigY8Loygug8vHTWhYAj9YysRO7hdNohXvalBbU+xLwGVU+FFC+pojN4FyfP25ySQDY1oV2gA/rPfmWfH3Q48mnULWIrnfk8y+QuwKcLZljYxdFh6Q/LmVG2cSx5zjNiGGs8rXkTBM/mDWreZdaQqr3S8IIX8X+GhG7h3fB1eTcDGQ0xvIF4yVL2vsAgnlpTyqc2MCyfiuTHYF48M3II6BOcw8HhsvpFp6qD+jHbIm+AyyTsQobsfOdSS1OoyWeCuu+LBkVeVoOkdWTyQem+95SPmOZ4uQciIt9I5IuWFgYF+6O3TtYV7XPvnBtxkY=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"The code you posted is a valid application of the producer/consumer pattern. If you want to use more TPL Dataflow, then I'd recommend looking into ActionBlock instead of BufferBlock (which essentially moves your consumer(s) into the dataflow mesh). And no, with multiple consumers, you can't guarantee FIFO because multiple items are processed at once.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"9f99ae37-3b8e-360a-b7f2-b2d78b9774fe","date":"2017-07-10T13:53:10Z","timestamp":1499694790,"authorUserId":"disqus:stephen_cleary"},{"_id":"9f99ae37-3b8e-360a-b7f2-b2d78b9774fe","authorName":"burak","authorEmailEncrypted":"mODj99h8SRFSevf6JqjLBILk9xg+cIrIW5kdff3x1QYviCkZFEO6kNmo9Bd1vlV1+hDf+gwkc9f5Aj4PDD/8kzQHZjQyf7ZkrdNC0oLqFxI9ylbRDnE2vgkMJ6yTpjgOPErGt/A2Oy/wwriYeaarYQMqpCrdUMVBLftH/x8vk3ISHQFKaTItpvw4o5mFGo0s5OBMXqzXOdgKF9U1fX6yXR5A2Cetfdou1deHphQGC9E8xhlP21+WwjXhrKBT1prapiHDL4J4hGP1/Azp0BlEMxvlupfFQMjSO1X1/EffW8lwuGeJ/cWlZjAt5LBVIrdR7BIFhh9OZtVrxc7rrv32QPc7iS/AwBsvZqctgNwZCtmueDAt26YY3g7uxosVt2Ty8J+9rB92AZkjLoqyQauwFwBt67gUWrCHZ2GiLu9sspc5WggE5zqGepxJHBI71FzaXSbLHLpepZGWWu1JTrSLb/8BiHtOabO7fSPyXPS5JJILauAfLEpILiUJGxpFRu1N7SCVmpc/A15ntPLq5NlsoTFBM56qFlPTaT8D2FTLmR+aMnBwpDEgVs3y/27awwCrvhjo0H2dZFJyeaCRpBB7z5KK5pvYC+XtciZboQhYXhEV+xVXCM3hqsoQvr3XOQ+vxngr7EgwJxp8hmxy7QedNCHUjET0UMCKmOOh8XAO+S8=","authorEmailMD5":"181f504d1045d08f580ebc4ce4f9a843","message":"Hi Stephen,\r\n\r\nThanks for your brief explanation. I have a program running as a windows service, an infinite loop performs producer-consumer pattern. I was using BlockingCollection<t> implementation for my purposes, then I decided to migrate to TPL as long as I investigate on TPL . So I build some code in my own way this and that. Would you mind to make time for reviewing my code ? I wonder if this code suitable for long running? Do you see any bottlenecks? I haven't used any parallell approach, if I want to use parallel, should I use it as you provided above \"Multiple consumers\" ? Can I ensure the processing order(FIFO) if I use multiple producers and consumers?  \r\n [https://gist.github.com/fabercs/a4c92abccbfeeaca92293386406d8ef3](https://gist.github.com/fabercs/a4c92abccbfeeaca92293386406d8ef3)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2017-07-10T06:11:45Z","timestamp":1499667105,"authorUserId":"disqus:disqus_30IsJOLcrN"},{"_id":"8e7ddf9f-8a4d-3827-9745-65dbf80ab7fc","authorName":"Stephen Cleary","authorEmailEncrypted":"SJHh1ImTiY1UCSKwsfy4vcX13+AGyXAOvf4i+DLSZSRQ48xwWkvwBjAF+8O4zacDq9S5eQWVlgnttP8dSQYrHV3OyB9VgW17X+DPAmPrlbvJkRzk1yUVhqhq3dEOHeBmaDtrZAaWCiN+ueSLUU6v+P0wvqm3gSslvFo85/giAwFY9yhQLonC8fNuqkPnPmpv4pFG7dkH/k5ZAS7wnMC4+x6F1OnR2PX4OLemb5ddk/0IvU8EzlIOytZwzrzyw+GI+I25NjzPeNAjy09T4czYAoczAYFD3k9TKpj8FEyiWZNRGEUVkZmdgOdrwrBLB3Axi7yQTy/p8tTfzHWKqRdcnUSnTXujsO9Bo1Dz8cQdtXZ38/CwxdgGPmhoFnH5GNzgXH9UbdzK1r9w33TFrtaIMJ+60OYFFgWINAnNybRivvdETgtAsUtMxUjrgjbd50uchQXgBVmstFE7WzJCa1iwR9Nm3LsjsLkm7kWSj2VS90yqnWfcbxC4GOl45Y7m00V588dHoH6MYSgFLJGtgbeqqOtx4K/uh3vkd3RFxNmQ/qNmKjMEbki5L1j+/Bwk75JzaDqNWfVXWGErMO/yHHWnZO1i0CUEu8Rkx6lffeyqODmCBab0wsqH0LOEIaTJyXHEKN5W+PSo8tpBFAhfNXoXxWid9rZhZhz+JaPFUBk7a+g=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"You cannot reset a block once it has completed. You'd need to create a new block if you want to start over. Or, you could just not complete the block as you mentioned - that would work fine. Many apps set up a dataflow mesh and just leave it operational.\r\n\r\nIf you only have one consumer, then (of course) it can only process one message at a time. You can attach multiple consumers to a producer/consumer queue, or you can change the queue to a mesh and use ActionBlock instead of BufferBlock. You can then set the MaxDegreeOfParallelism option on the ActionBlock to enable parallel consumption.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"6f51f1e4-4ed7-3083-af13-f118de7f6187","date":"2017-10-04T15:59:51Z","timestamp":1507132791,"authorUserId":"disqus:stephen_cleary"},{"_id":"df6f76ca-9d7e-3bae-89db-75f6e636d0f9","authorName":"Valera Valera","authorEmailEncrypted":"pnSxK4a6teYa0q3nHfgumyGN4Qkparr129/GVpnNyvFILu6EFIwdnbu/i0JGNI3QgFg563EGoUs7C1SMJK4PVb6f8fO0n0ihhgZmBkJa0MQyrd30b0Giymy4PuyNWGyCUs11HmAPcu4PWSEIn1YH39lfeddvRyX6nWSJNB8Hs4QPUPIOfrhtSvRDB+IYrR1lZL2GW9E/y4hVkWv1bd6TSxvzj+SFdsjFzqGBvQHdA5ReAIF593oDv3VA/Pp2fSPofCrXfKsM50x7HRufROtVQGcM8nUr9LJ9vZcJcrWej+6trP1deCkb2aOhK2Z0pwFUeijr5dIZxHwcT/7FzX0yL8iG/yaqx8RgssEw39cEAA/b9HLHGsj50wplF5UIkWo82S5LSce+Kwm7dNilnW5KPGBIRdQt8SuszYhQv4w5APtUciyifyI8pMr5BQCxn+bcGNRMBOZFVX5JMHERwENPCKoLYSt4Yc446xClCk7LDwHa1r+mdVSwL9hTLU1gIQ6rlRZEh7/A6epHa5JpD0rnDzs6k+1Yp30RUOIO96oEYG3zWMYrxHOIl8EqR2qHJkswDekB1oZCqXAX43e+ARFruikMsCV5Bo3+JGt0f1xO/mIq82VsLn2LKVOhOAki5lFNMv6pZke2Bd9QHA5zFlpt2AQl23mwEl8J0ooT6MrU4G8=","authorEmailMD5":"614c725eb605a8a6268d23b7d05aab13","message":"[https://stackoverflow.com/questions/48337739/blocking-collection-when-collect-results-inside-actionblock](https://stackoverflow.com/questions/48337739/blocking-collection-when-collect-results-inside-actionblock)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"","date":"2018-01-19T09:27:50Z","timestamp":1516354070,"authorUserId":"disqus:disqus_SAck8xFJHW"},{"_id":"5a5e4c2b-1e3d-32ef-a819-2b778e8dd21f","authorName":"Ondra Medek","authorEmailEncrypted":"b54bo8B+SNzxX2VGLibupV97+3yOiwz50iKhulVYqupIleHzKaYUfOTHfu0xKoy11sHiz4YwjNxeWxg9HVs5sisXRh7bRqGuEPx0LiRMPyUV36edTqP1s4s+j1C14z2qP6Ph5ebGuTd3fNdbLjDsXjhamwxauXi0TtzbxnZbwLE92ZElhDbwdAK6KD3hD3jCxtGPJ+rMKuVYLO1gZbfTAuelnaRxZfHmzsJevHZ5Ud/B/8iZujOpBH2Kvig4O13cHwcnzXYK4t55521vKXk5w616i/7Eao7hZ5ueRAjBLVtkegd3E+7l7NZ28sKKxl2l+23nxY0UuHl8oaxDlBE+A9unslPMpUP1f/XNjr2vrT3gQH9tkJvApHBYh7M25B5DW+/GHiw6I47aXNVpyBn6vM8CTb9QBFN78IwdQfXvUGJgktpZwPrdOabo5gVPaLhcbcHmmi5dEnNoX8I3eWsJQZonmYQbZtJ/gGDrZzhJaqRqu//7i+0GqUByRXtJyJlCBmqZAUHVWRM34QOLZo5Z457YOsGXqwK2jvj2htWUw1QzpIiBEmv0j6SFfjy+Nd+W3C+o/a1rEUEEjXdwg7pz7NpcwcQvtHVsN1P8BWt3qBjqveSvEDWooN/3cbkrND+GQ0jUIMgnnyMvMTW8b0EIcCjgHUCOF3zXmW8Gjrj552Q=","authorEmailMD5":"788da16a4617bd79f2bf91d8dc258455","message":"But the Microsoft doc uses TryReceive for the async multi consumers, see [https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-implement-a-producer-consumer-dataflow-pattern](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-implement-a-producer-consumer-dataflow-pattern)","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"0ba63598-155f-3ab5-aa2d-7f8b97681c69","date":"2018-02-04T21:00:31Z","timestamp":1517778031,"authorUserId":"disqus:xmedeko"},{"_id":"e26a04d9-4aa1-3dcc-ba7e-6a14f3c380e8","authorName":"Stephen Cleary","authorEmailEncrypted":"RndSCXlvw492WR0mCz3okJUpXPmj/xu/XTpopTp2DQlvQj0OnghAW/nlFV2AM1cx/O1psdOWUvvQDYvyLzs3v+kOqe0iEsF0+qa/yZ1qJdt9fDWpZIIwXrvuBx3uXWiCyEdi9Runa+K2luXO56sjz81bPZWZQELMmRVjGaHEQoWDSp1CcWudzXed6cUudUK2Jrt+kO4TDL+A4/LDX3bCvJOjbaS5qNuFlexTaFeIJsTWv3792K7sBXcGvWP/9qC9j6TJADBhwlWbU8EZPzhfpujavNOs8c9u5iIkxWJY1h2OOn/Vq/mTPIesbMhTY36o+gN+aK1nwAbTrCQov0Z98uQFE2dGXA6ab9gGpup2XO8dc5CPT6Iv9lN6dnLTdt0Q7JPGxg403YykcglKdzS32ivxCoMKH/tbAWQD36im9xfp2arddvS3KHiZbfbz1mtqZAjf2LiOlrNmIdJDV/g1uoK5PJtUVDbDzepxv+siF2spL5w0ZuFLpPz6bdvt4IHrspNdW6EcVme8Cd5wMBHfDA+cYjooeCHx4cAwqhigmuxp91LmGbUx4mpJJsFCpc2uf9MmUD4whUbp3L6Tx+NOoLmOLaubLfrdfKteVS/HKM6i7yJ4vbUYwhaNFQTOS3orfnnuA/M22l+suKWoy2tECecJSlZCQRAR4lcwHKLpaWo=","authorEmailMD5":"ad2250182ff26a84dda974e50cd94382","message":"Yes, as long as they await OutputAvailableAsync, then using TryReceive works.","postId":"2012_11_async-producerconsumer-queue-using-7d55b643-a325-3ba0-9ffa-7ec6b0363eaf","replyTo":"5a5e4c2b-1e3d-32ef-a819-2b778e8dd21f","date":"2018-02-05T18:58:12Z","timestamp":1517857092,"authorUserId":"disqus:stephen_cleary"}]